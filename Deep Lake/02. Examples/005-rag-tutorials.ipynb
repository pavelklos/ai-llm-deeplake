{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (RAG)\n",
    "- [RAG](https://docs.activeloop.ai/examples/rag)\n",
    "  - [RAG Quickstart](https://docs.activeloop.ai/examples/rag/quickstart)\n",
    "  - [RAG Tutorials](https://docs.activeloop.ai/examples/rag/tutorials)\n",
    "    - [Vector Store Basics](https://docs.activeloop.ai/examples/rag/tutorials/vector-store-basics)\n",
    "    - [Vector Search Options](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options)\n",
    "      - [LangChain API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/langchain-api)\n",
    "      - [**Deep Lake Vector Store API**](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/vector-store-api)\n",
    "      - [Managed Database REST API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/rest-api)\n",
    "    - [Customizing Your Vector Store](https://docs.activeloop.ai/examples/rag/tutorials/step-4-customizing-vector-stores)\n",
    "    - [Image Similarity Search](https://docs.activeloop.ai/examples/rag/tutorials/image-similarity-search)\n",
    "    - [Improving Search Accuracy using Deep Memory](https://docs.activeloop.ai/examples/rag/tutorials/deepmemory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9134e12-66df-4b48-915d-a3b9f5e1c550",
   "metadata": {},
   "source": [
    "## RAG Tutorials (Vector Search Options) (Deep Lake Vector Store API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17fc33e8-32b1-48cd-9544-85b792392f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"deeplake[enterprise]\" langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd500c5-2201-4608-af4f-bfe6cc2d4ce1",
   "metadata": {},
   "source": [
    "### Vector Search on the Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2294fc-8df0-4420-8e0d-4218cb2186e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deeplake.core.vectorstore import VectorStore\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "914b6a0c-dcdf-4773-84fa-757d1dde4d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5627061a-6d83-49f1-b586-c4c81bd1075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://activeloop/paul_graham_essay already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# Load the same vector store used in the Quickstart and run embeddings search\n",
    "#   based on a user prompt using the Deep Lake Vector Store module\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = <OPENAI_API_KEY>\n",
    "\n",
    "vector_store_path = 'hub://activeloop/paul_graham_essay'\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    path = vector_store_path,\n",
    "    read_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459c02b2-03c0-499e-9910-1af18f349cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an embedding function using OpenAI\n",
    "\n",
    "def embedding_function(texts, model=\"text-embedding-ada-002\"):\n",
    "   \n",
    "   if isinstance(texts, str):\n",
    "       texts = [texts]\n",
    "\n",
    "   texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
    "   \n",
    "   return [data.embedding for data in openai.embeddings.create(input = texts, model=model).data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906d7a8-14d0-41f7-a3c7-ad539bc068f1",
   "metadata": {},
   "source": [
    "#### Simple Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b2b73e-4986-4548-ab37-f9670b00797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the first programs he tried writing?\"\n",
    "\n",
    "search_results = vector_store.search(embedding_data=prompt, \n",
    "                                     embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888a28df-4581-4a58-8c14-7b8356699b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f16a5-494f-4533-89fb-b046f05350d0",
   "metadata": {},
   "source": [
    "#### Filter Search Using UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba1a9e9-d7c2-4860-b96b-c59829855181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fn(x):\n",
    "    # x is a single row in Deep Lake, 'text' is the tensor name, .data()['value'] is the method for fetching the data\n",
    "    return \"program\" in x['text'].data()['value'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3401bd4f-47e6-4654-8532-87b9744eb82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1263.74it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are the first programs he tried writing?\"\n",
    "\n",
    "search_results_filter = vector_store.search(embedding_data = prompt, \n",
    "                                            embedding_function = embedding_function,\n",
    "                                            filter = filter_fn,\n",
    "                                            k = 10,\n",
    "                                            distance_metric = 'l2',\n",
    "                                            exec_option = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72e8d3e-6d1c-441b-9b65-ddc3f4f5327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([\"program\" in result for result in search_results_filter[\"text\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973aa5c-0138-4e15-bf30-97ed3a683673",
   "metadata": {},
   "source": [
    "#### Filter Search Using Metadata Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b30821e5-03e9-41a8-8342-f93c3e1e753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1162.18it/s]\n"
     ]
    }
   ],
   "source": [
    "search_results_filter = vector_store.search(embedding_data = prompt, \n",
    "                                            embedding_function = embedding_function,\n",
    "                                            filter = {\"metadata\": {\"source\": \"paul_graham_essay.txt\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6bb3ce-5145-4735-968b-a7c095c70483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'paul_graham_essay.txt'},\n",
       " {'source': 'paul_graham_essay.txt'},\n",
       " {'source': 'paul_graham_essay.txt'},\n",
       " {'source': 'paul_graham_essay.txt'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results_filter[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc81cf30-fafa-44c7-9b68-f8f4f53da127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paul_graham_essay.txt\n",
      "paul_graham_essay.txt\n",
      "paul_graham_essay.txt\n",
      "paul_graham_essay.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for result in search_results_filter[\"metadata\"]:\n",
    "#     print(result)\n",
    "[print(result[\"source\"]) for result in search_results_filter[\"metadata\"]]\n",
    "\n",
    "all([\"paul_graham_essay.txt\" in result[\"source\"] for result in search_results_filter[\"metadata\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d162aa-7023-4398-ad1b-be1d8327a4d6",
   "metadata": {},
   "source": [
    "#### Filter Search using TQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab8b1208-ade0-4160-8b0d-c39a798047d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://activeloop/twitter-algorithm already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# Load a larger Vector Store for running more interesting queries\n",
    "\n",
    "vector_store_path = \"hub://activeloop/twitter-algorithm\"\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    path = vector_store_path,\n",
    "    read_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9318c567-9b4a-47af-b33d-a12444bd685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What does the python code do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316ce813-b382-48b5-98f7-bda806b77703",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_function(prompt)[0]\n",
    "\n",
    "# Format the embedding array or list as a string, so it can be passed in the REST API request.\n",
    "embedding_string = \",\".join([str(item) for item in embedding])\n",
    "\n",
    "tql_query = f\"select * from (select text, metadata, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score where contains(text, 'python') or contains(metadata['source'], '.py')) order by score desc limit 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b80a8c9d-db7f-4703-aa85-b6a96863377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = vector_store.search(query = tql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ed37de9-7dcd-4a34-93a8-d2ac629216c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': './the-algorithm/ann/src/main/python/dataflow/worker_harness/Dockerfile'},\n",
       " {'source': './the-algorithm/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/lolly/score.py'},\n",
       " {'source': './the-algorithm/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/lolly/BUILD'},\n",
       " {'source': './the-algorithm/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/BUILD'},\n",
       " {'source': './the-algorithm/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/tf_model/BUILD'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd840f-9b85-4a85-9d34-ee3b6ff6bc03",
   "metadata": {},
   "source": [
    "### Vector Search Using the Managed Tensor Database (Server-Side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "545352ac-cb27-4d4d-aa47-e49820a6f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = VectorStore(\n",
    "#     path = \"hub://<org_id>/<dataset_name>\",\n",
    "#     runtime = {\"tensor_db\": True}\n",
    "# )\n",
    "\n",
    "search_results = vector_store.search(embedding_data=prompt, \n",
    "                                     embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "658ff855-3724-4dbd-980a-1e4cd26a6fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': './the-algorithm/ann/src/main/python/dataflow/worker_harness/Dockerfile'},\n",
       " {'source': './the-algorithm/.git/logs/refs/remotes/origin/HEAD'},\n",
       " {'source': './the-algorithm/.git/logs/refs/heads/main'},\n",
       " {'source': './the-algorithm/.git/logs/HEAD'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[\"metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b85145f0-c207-469b-9faa-fdb741385b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RUN \\\\\\n  # Add Deadsnakes repository that has a variety of Python packages for Ubuntu.\\n  # See: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\\n  apt-key adv --keyserver keyserver.ubuntu.com --recv-keys F23C5A6CF475977595C89F51BA6932366A755776 \\\\\\n  && echo \"deb http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal main\" >> /etc/apt/sources.list.d/custom.list \\\\\\n  && echo \"deb-src http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal main\" >> /etc/apt/sources.list.d/custom.list \\\\\\n  && apt-get update \\\\\\n  && apt-get install -y curl \\\\\\n  python3.7 \\\\\\n  # With python3.8 package, distutils need to be installed separately.\\n  python3.7-distutils \\\\\\n  python3-dev \\\\\\n  python3.7-dev \\\\\\n  libpython3.7-dev \\\\\\n  python3-apt \\\\\\n  gcc \\\\\\n  g++ \\\\\\n  && rm -rf /var/lib/apt/lists/*\\nRUN update-alternatives --install /usr/bin/python python /usr/bin/python3.7 10\\nRUN rm -f /usr/bin/python3 && ln -s /usr/bin/python3.7 /usr/bin/python3\\nRUN \\\\\\n  curl https://bootstrap.pypa.io/get-pip.py | python \\\\\\n  && pip3 install pip==22.0.3 \\\\\\n  && python3 -m pip install --no-cache-dir apache-beam[gcp]==2.39.0\\n# Verify that there are no conflicting dependencies.\\nRUN pip3 check'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[\"text\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
