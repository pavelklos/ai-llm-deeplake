{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (RAG)\n",
    "- [RAG](https://docs.activeloop.ai/examples/rag)\n",
    "  - [RAG Quickstart](https://docs.activeloop.ai/examples/rag/quickstart)\n",
    "  - [RAG Tutorials](https://docs.activeloop.ai/examples/rag/tutorials)\n",
    "    - [Vector Store Basics](https://docs.activeloop.ai/examples/rag/tutorials/vector-store-basics)\n",
    "    - [Vector Search Options](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options)\n",
    "      - [LangChain API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/langchain-api)\n",
    "      - [Deep Lake Vector Store API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/vector-store-api)\n",
    "      - [Managed Database REST API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/rest-api)\n",
    "    - [Customizing Your Vector Store](https://docs.activeloop.ai/examples/rag/tutorials/step-4-customizing-vector-stores)\n",
    "    - [Image Similarity Search](https://docs.activeloop.ai/examples/rag/tutorials/image-similarity-search)\n",
    "    - [**Improving Search Accuracy using Deep Memory**](https://docs.activeloop.ai/examples/rag/tutorials/deepmemory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9134e12-66df-4b48-915d-a3b9f5e1c550",
   "metadata": {},
   "source": [
    "## RAG Tutorials (Improving Search Accuracy using Deep Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b3e3d-835e-488a-9ff9-4166fd73edbb",
   "metadata": {},
   "source": [
    "### Use Deep Memory to Improve the Accuracy of your Vector Search\n",
    "*Deep Memory computes a transformation that converts your embeddings into an embedding space that is tailored for your use case, based on several examples for which the most relevant embedding is known. This can increase the accuracy of your Vector Search by up to 22%.*\n",
    "\n",
    "*In this example, we'll use Deep Memory to improve the accuracy of Vector Search on the SciFact dataset, where the input prompt is a scientific claim, and the search result is the corresponding abstract.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13442fb8-c23a-4b37-89c3-7ecb0d30ef5f",
   "metadata": {},
   "source": [
    "#### Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69acbcf4-e080-43d5-86d5-487e58f4a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007323c9-4013-4eda-a84f-f9668951a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deeplake import VectorStore\n",
    "# from deeplake.core.vectorstore.deeplake_vectorstore import VectorStore\n",
    "# from deeplake.core.vectorstore import VectorStore\n",
    "import os\n",
    "import getpass\n",
    "import datasets\n",
    "import openai\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19538e8b-0138-46f6-a171-03541a3f0811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105001734a9a44728f5498fd1a4c4342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0617943d8140ad8c05fa4188fb3748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the dataset locally\n",
    "\n",
    "# corpus = datasets.load_dataset(\"scifact\", \"corpus\")\n",
    "corpus = datasets.load_dataset(\"scifact\", \"corpus\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d77cb6-d19d-4f5a-b194-11dc94379a72",
   "metadata": {},
   "source": [
    "#### Creating the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc9375f-3190-412e-8027-12265374851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an embedding function for the text data and create a Deep Lake Vector Store in our Managed Database.\n",
    "# Deep Memory is only available for Vector Stores in our Managed Database.\n",
    "\n",
    "def embedding_function(texts, model=\"text-embedding-ada-002\"):\n",
    "   \n",
    "   if isinstance(texts, str):\n",
    "       texts = [texts]\n",
    "\n",
    "   texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
    "   # return [data['embedding']for data in openai.Embedding.create(input = texts, model=model)['data']]\n",
    "   return [data.embedding for data in openai.embeddings.create(input = texts, model=model).data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32b2c22-27e5-4ad3-9ed2-018a22463e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SciFact dataset\n",
    "# - https://huggingface.co/datasets/allenai/scifact\n",
    "\n",
    "# path = 'hub://<org_id>/<vector_store_name>'\n",
    "path = 'hub://pavelkloscz/ds-scifact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be660c69-1a37-4efd-ac22-a8cd5f88558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "vectorstore = VectorStore(\n",
    "    path=path,\n",
    "    embedding_function=embedding_function,\n",
    "    runtime={\"tensor_db\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4db68b-c292-48d5-854d-46956db67b44",
   "metadata": {},
   "source": [
    "#### Adding data to the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a4a2ac-8425-47b1-b32b-13da9a5d0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the SciFact dataset and add it to our Vector Store. In this example, we embed the abstracts of the scientific papers.\n",
    "# Normally, the id tensor is auto-populated, but in this case, we want to use the ids in the SciFact dataset, in order to use\n",
    "#   the internal connection between ids, abstracts, and claims, that already exists in SciFact.\n",
    "\n",
    "ids = [f\"{id_}\" for id_ in corpus[\"train\"][\"doc_id\"]]\n",
    "texts = [' '.join(text) for text in corpus[\"train\"][\"abstract\"]]\n",
    "metadata = [{\"title\": title} for title in corpus[\"train\"][\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54464ef1-cdae-46d3-887d-df6b111f9084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 5183 embeddings in 11 batches of size 500:: 100%|█████████████████████████████████████████████████████| 11/11 [02:06<00:00, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://pavelkloscz/ds-scifact', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype       shape       dtype  compression\n",
      "  -------    -------     -------     -------  ------- \n",
      "   text       text      (5183, 1)      str     None   \n",
      " metadata     json      (5183, 1)      str     None   \n",
      " embedding  embedding  (5183, 1536)  float32   None   \n",
      "    id        text      (5183, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vectorstore.add(\n",
    "    text=texts,\n",
    "    id=ids,\n",
    "    embedding_data=texts,\n",
    "    embedding_function=embedding_function,\n",
    "    metadata=metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a898ea-cb73-4474-b669-1f32b5225a73",
   "metadata": {},
   "source": [
    "#### Generating claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49108997-bdaa-4d9e-938c-a3e2b660fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a relationship between the claims and their corresponding most relevant abstracts.\n",
    "# This correspondence already exists in the SciFact dataset, and we extract that information using the helper function below.\n",
    "\n",
    "def preprocess_scifact(claims_dataset, dataset_type=\"train\"):\n",
    "\n",
    "    # Using a dictionary to store unique claims and their associated relevances\n",
    "    claims_dict = {}\n",
    "\n",
    "    for item in claims_dataset[dataset_type]:\n",
    "        claim = item['claim']  # Assuming 'claim' is the field for the question\n",
    "        relevance = item['cited_doc_ids']  # Assuming 'cited_doc_ids' is the field for relevance\n",
    "        relevance = [(str(r), 1) for r in relevance]\n",
    "\n",
    "        # Check for non-empty relevance\n",
    "        if claim not in claims_dict:\n",
    "            claims_dict[claim] = relevance\n",
    "        else:\n",
    "            # If the does not exist in the dictionary, append the new relevance\n",
    "            if relevance not in claims_dict[claim]:\n",
    "                claims_dict[claim].extend(relevance)\n",
    "\n",
    "    # Split the dictionary into two lists: claims and relevances\n",
    "    claims = list(claims_dict.keys())\n",
    "    relevances = list(claims_dict.values())\n",
    "    return claims, relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bcc941-3384-4d1f-ad75-2d289cf9c37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7b9f7a1ec84bc3918b5f868b20ee37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1261 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f1b5c932664dfdb3672162d452bf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ea666952384f998f1341e5e71226a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "claims_dataset = datasets.load_dataset('scifact', 'claims')\n",
    "claims, relevances = preprocess_scifact(claims_dataset, dataset_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8764b-4080-4791-bd9d-4fa56035af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 10 claims and their relevant abstracts.\n",
    "# The relevances are a list of tuples, where each the id corresponds to the id tensor value in\n",
    "#   the Abstracts Vector Store, and 1 indicates a positive relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "121a3a15-18a6-43e3-a592-8633ebc187d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-dimensional biomaterials lack inductive properties.',\n",
       " '1 in 5 million in UK have abnormal PrP positivity.',\n",
       " '1-1% of colorectal cancer patients are diagnosed with regional or distant metastases.',\n",
       " '10% of sudden infant death syndrome (SIDS) deaths happen in newborns aged less than 6 months.',\n",
       " '32% of liver transplantation programs required patients to discontinue methadone treatment in 2001.',\n",
       " '4-PBA treatment decreases endoplasmic reticulum stress in response to general endoplasmic reticulum stress markers.',\n",
       " '4-PBA treatment raises endoplasmic reticulum stress in response to general endoplasmic reticulum stress markers.',\n",
       " '40mg/day dosage of folic acid and 2mg/day dosage of vitamin B12 does not affect chronic kidney disease (CKD) progression.',\n",
       " \"5'-nucleotidase metabolizes 6MP.\",\n",
       " '50% of patients exposed to radiation have activated markers of mesenchymal stem cells.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b2340f-22ec-4910-8479-206a82d6bb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('31715818', 1)],\n",
       " [('13734012', 1)],\n",
       " [('22942787', 1)],\n",
       " [('2613775', 1)],\n",
       " [('44265107', 1)],\n",
       " [('32587939', 1)],\n",
       " [('32587939', 1)],\n",
       " [('33409100', 1), ('33409100', 1)],\n",
       " [('641786', 1)],\n",
       " [('22080671', 1)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevances[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1b8f7-4ae1-40c0-bd65-4848c62f40bd",
   "metadata": {},
   "source": [
    "#### Running the Deep Memory Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b626a116-ad95-477f-9f91-6f6f647d90c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "DeepMemoryAccessError",
     "evalue": "Deep Memory is not available for organizations on Community plan.Please, consider upgrading or start a free trial at https://app.activeloop.ai/pricing.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDeepMemoryAccessError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run a Deep Memory training, which runs asynchronously and executes on our managed service.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m job_id = \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelevance\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deep_memory\\deep_memory.py:45\u001b[39m, in \u001b[36maccess_control.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m DeepMemoryAccessError()\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[31mDeepMemoryAccessError\u001b[39m: Deep Memory is not available for organizations on Community plan.Please, consider upgrading or start a free trial at https://app.activeloop.ai/pricing."
     ]
    }
   ],
   "source": [
    "# Run a Deep Memory training, which runs asynchronously and executes on our managed service.\n",
    "\n",
    "job_id = vectorstore.deep_memory.train(\n",
    "    queries = claims,\n",
    "    relevance = relevances,\n",
    "    embedding_function = embedding_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56131a-4f59-499e-a161-879fd7924c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the Deep Memory training jobs for this Vector Store can be listed using the command below.\n",
    "# The PROGRESS tells us the state of the training job, as well as the recall improvement on the data.\n",
    "\n",
    "# recall@k corresponds to the percentage of rows for which the correct (most relevant) answer was returned in the top k vector search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611bae7-785f-46d4-b0b1-c263d7854614",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.deep_memory.list_jobs()\n",
    "\n",
    "# [OUTPUT]\n",
    "# This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop-test/test-deepmemory-ivo\n",
    "# ID                        STATUS     RESULTS                        PROGRESS       \n",
    "# 6525a94bbfacbf7e75a08c76  completed  recall@10: 0.00% (+0.00%)      eta: 45.5 seconds\n",
    "#                                                                     recall@10: 0.00% (+0.00%)\n",
    "# 6538186bc1d2ffd8e8cd3b49  completed  recall@10: 85.81% (+21.78%)    eta: 1.9 seconds\n",
    "#                                                                     recall@10: 85.81% (+21.78%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ed33f-80c1-437d-b9c7-b6772108b183",
   "metadata": {},
   "source": [
    "#### Evaluating Deep Memory's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd2939-ab76-430d-ab9a-57a6c93f832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the recall improvement for an evaluation dataset that was not used in the training process.\n",
    "# Deep Memory inference, and by extension this evaluation process, runs on the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa505db-2d52-4516-a4d1-18b456e2af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_claims, validation_relevances = preprocess_scifact(claims_dataset, dataset_type=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c98abd-7536-4c5c-a4ec-fec0b0af16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = vectorstore.deep_memory.evaluate(\n",
    "    queries = validation_claims,\n",
    "    relevance = validation_relevances,\n",
    "    embedding_function = embedding_function,\n",
    ")\n",
    "\n",
    "# [OUTPUT]\n",
    "# ---- Evaluating without Deep Memory ---- \n",
    "# Recall@1:\t  44.2%\n",
    "# Recall@3:\t  56.9%\n",
    "# Recall@5:\t  61.3%\n",
    "# Recall@10:\t  67.3%\n",
    "# Recall@50:\t  77.2%\n",
    "# Recall@100:\t  79.9%\n",
    "# ---- Evaluating with Deep Memory ---- \n",
    "# Recall@1:\t  60.4%\n",
    "# Recall@3:\t  67.6%\n",
    "# Recall@5:\t  71.7%\n",
    "# Recall@10:\t  75.4%\n",
    "# Recall@50:\t  79.1%\n",
    "# Recall@100:\t  80.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e40125-41cf-45e8-8fe4-478ad88500c8",
   "metadata": {},
   "source": [
    "#### Using Deep Memory in your Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532d91c-d554-444b-ba86-0b30b455bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use Deep Memory in your applications, specify the deep_memory = True parameter during vector search.\n",
    "# If you are using the LangChain integration, you may specify this parameter during Vector Store initialization.\n",
    "# Let's try searching embedding using a prompt, with and without Deep Memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed74476-40e0-42ed-8ce2-7fe78799a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Which diseases are inflammation-related processes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a02f29-6b98-401f-89c5-f4b45219fc21",
   "metadata": {},
   "source": [
    "**Without Deep Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c30a9d8-9bb4-4b20-a788-f4eb3c82cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.search(embedding_data = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054db0f6-2b27-412d-a506-dba2495f1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['text']\n",
    "\n",
    "# [OUTPUT]\n",
    "# ['Inflammation is a fundamental protective response that sometimes goes awry and becomes a major cofactor in the pathogenesis of many chronic human diseases, including cancer.',\n",
    "#  'Kidney diseases, including chronic kidney disease (CKD) and acute kidney injury (AKI), are associated with inflammation.',\n",
    "#  'BACKGROUND Persistent inflammation has been proposed to contribute to various stages in the pathogenesis of cardiovascular disease.',\n",
    "#  'Inflammation accompanies obesity and its comorbidities-type 2 diabetes, non-alcoholic fatty liver disease and atherosclerosis, among others-and may contribute to their pathogenesis.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecce4e-1b3c-40f3-9f6c-07f047fa4a78",
   "metadata": {},
   "source": [
    "**With Deep Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b5d0e-384a-4521-bba9-78447df9b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dm = vectorstore.search(embedding_data = prompt, deep_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5a888-b3ed-4f96-9023-e02ea14fc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dm['text']\n",
    "\n",
    "# [OUTPUT]\n",
    "# ['Kidney diseases, including chronic kidney disease (CKD) and acute kidney injury (AKI), are associated with inflammation.',\n",
    "#  'OBJECTIVES Calcific aortic valve (AV) disease is known to be an inflammation-related process.',\n",
    "#  \"Crohn's disease and ulcerative colitis, the two main types of chronic inflammatory bowel disease, are multifactorial conditions of unknown aetiology.\",\n",
    "#  'BACKGROUND Two inflammatory disorders, type 1 diabetes and celiac disease, cosegregate in populations, suggesting a common genetic origin.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8b875-f900-482b-934d-dad8ace19cef",
   "metadata": {},
   "source": [
    "**We observe that there are overlapping results for both search methods, but 50% of the answers differ.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
