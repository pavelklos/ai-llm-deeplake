{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (RAG)\n",
    "- [RAG](https://docs.activeloop.ai/examples/rag)\n",
    "  - [RAG Quickstart](https://docs.activeloop.ai/examples/rag/quickstart)\n",
    "  - [RAG Tutorials](https://docs.activeloop.ai/examples/rag/tutorials)\n",
    "    - [Vector Store Basics](https://docs.activeloop.ai/examples/rag/tutorials/vector-store-basics)\n",
    "    - [Vector Search Options](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options)\n",
    "      - [LangChain API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/langchain-api)\n",
    "      - [Deep Lake Vector Store API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/vector-store-api)\n",
    "      - [Managed Database REST API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/rest-api)\n",
    "    - [Customizing Your Vector Store](https://docs.activeloop.ai/examples/rag/tutorials/step-4-customizing-vector-stores)\n",
    "    - [Image Similarity Search](https://docs.activeloop.ai/examples/rag/tutorials/image-similarity-search)\n",
    "    - [Improving Search Accuracy using Deep Memory](https://docs.activeloop.ai/examples/rag/tutorials/deepmemory)\n",
    "  - [LangChain Integration](https://docs.activeloop.ai/examples/rag/langchain-integration)\n",
    "  - [LlamaIndex Integration](https://docs.activeloop.ai/examples/rag/llamaindex-integration)\n",
    "  - [**Managed Tensor Database**](https://docs.activeloop.ai/examples/rag/managed-database)\n",
    "    - [**REST API**](https://docs.activeloop.ai/examples/rag/managed-database/rest-api)\n",
    "    - [**Migrating Datasets to the Tensor Database**](https://docs.activeloop.ai/examples/rag/managed-database/migrating-datasets-to-the-tensor-database)\n",
    "  - [Deep Memory](https://docs.activeloop.ai/examples/rag/deep-memory)\n",
    "    - [How it Works](https://docs.activeloop.ai/examples/rag/deep-memory/how-it-works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9134e12-66df-4b48-915d-a3b9f5e1c550",
   "metadata": {},
   "source": [
    "## RAG (Managed Tensor Database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290e7d6-996b-498e-bce4-2b2defeaafc3",
   "metadata": {},
   "source": [
    "### Overview of Deep Lake's Managed Tensor Database\n",
    "- *Deep Lake offers a serverless Managed Tensor Database that eliminates the complexity of self-hosting and substantially lowers costs. Currently, it only supports dataset queries, including vector search, but additional features for creating and modifying data being added in December 2023.*<br>\n",
    "- *Comparison of Deep Lake as a Managed Database vs Embedded Database*<br>\n",
    "[DeepLake (Embedded vs Managed)](https://docs.activeloop.ai/~gitbook/image?url=https%3A%2F%2Fcontent.gitbook.com%2Fcontent%2FWOs95B2h3lcO4dwXDRJ3%2Fblobs%2FK3tTkpXoP4wBU4GBgBsc%2FDeep_Lake_Embedded_vs_Managed.png&width=400&dpr=3&quality=100&sign=df2cb5c0&sv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f884e-e9f3-464e-b074-e20726b3d311",
   "metadata": {},
   "source": [
    "#### User Interfaces\n",
    "**LangChain and LlamaIndex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61795465-e2c9-4fa6-bed9-af4ab9b32348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the Managed Vector Database in LangChain or Llama Index, specify dataset_path during Vector Store creation.\n",
    "\n",
    "# dataset_path = hub://org_id/dataset_name and runtime = {\"tensor_db\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362a3de-772a-4b04-80c5-bf6ee278a2b3",
   "metadata": {},
   "source": [
    "### REST API\n",
    "*Standalone REST API is available for interacting with the Managed Database*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e984564-b30b-4f2d-ba1a-b0c5b419e6d5",
   "metadata": {},
   "source": [
    "#### Overview of the Managed Database REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7479c6b5-1e15-4e73-9b6c-b33cb426ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Lake Tensor Database can be accessed via REST API.\n",
    "# The datasets must be stored in the Tensor Database by specifying the deeplake_path\n",
    "\n",
    "# deeplake_path = hub://org_id/dataset_name and runtime = {\"tensor_db\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a1ce4f-3bae-4f6d-b1ff-8eaeb36e9275",
   "metadata": {},
   "source": [
    "#### Querying via the REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb296b23-0a0d-49c9-a82f-80beb283d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The primary input to the query API is a query string that contains all the necessary information for\n",
    "#   executing the query, including the path to the Deep Lake data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b001e18-c0c1-4d05-bca6-06f1f0058ec7",
   "metadata": {},
   "source": [
    "**Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5348c295-9564-40a7-8419-5ce12a879734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://app.activeloop.ai/api/query/v1\"\n",
    "\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer {user_token}\"\n",
    "#     }\n",
    "\n",
    "# # Format the embedding array or list as a string, so it can be passed in the REST API request.\n",
    "# embedding_string = \",\".join([str(item) for item in embedding])\n",
    "\n",
    "# request = {\n",
    "#     \"query\": f\"select * from (select text, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score from \\\"{dataset_path}\\\") order by score desc limit 5\",\n",
    "#     \"as_list\": True/False # Defaults to True.\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5447b-2b9b-4cf0-9920-9433c9cde102",
   "metadata": {},
   "source": [
    "**Response**<br>\n",
    "**as_list = True** (default)<br>\n",
    "Returns a list of jsons, one per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ce36a2-18ef-4537-ba66-26f1d96beff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"message\": \"Query successful.\",\n",
    "#   \"tensors\": [\n",
    "#     \"text\",\n",
    "#     \"score\"\n",
    "#   ],\n",
    "#   \"data\": [\n",
    "#     {\n",
    "#       \"text\": \"# Twitter's Recommendation Algorithm\\n\\nTwitter's Recommendation Algorithm is a set of services and jobs that are responsible for constructing and serving the\\nHome Timeline. For an introduction to how the algorithm works, please refer to our [engineering blog](https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm). The\\ndiagram below illustrates how major services and jobs interconnect.\\n\\n![](docs/system-diagram.png)\\n\\nThese are the main components of the Recommendation Algorithm included in this repository:\",\n",
    "#       \"score\": 22.59016227722168\n",
    "#     },\n",
    "#     {\n",
    "#       \"text\": \"![](docs/system-diagram.png)\\n\\nThese are the main components of the Recommendation Algorithm included in this repository:\",\n",
    "#       \"score\": 22.5976619720459\n",
    "#     },...\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150d357-e12e-4d58-86c4-3f45934b151d",
   "metadata": {},
   "source": [
    "**Response**<br>\n",
    "**as_list = False**<br>\n",
    "Returns a list of values per tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75636857-0936-494c-86cb-fff96a74305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"message\": \"Query successful.\",\n",
    "#   \"tensors\": [\n",
    "#     \"text\",\n",
    "#     \"score\"\n",
    "#   ],\n",
    "#   \"data\": {\n",
    "#     \"text\": [\n",
    "#       \"# Twitter's Recommendation Algorithm\\n\\nTwitter's Recommendation Algorithm is a set of services and jobs that are responsible for constructing and serving the\\nHome Timeline. For an introduction to how the algorithm works, please refer to our [engineering blog](https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm). The\\ndiagram below illustrates how major services and jobs interconnect.\\n\\n![](docs/system-diagram.png)\\n\\nThese are the main components of the Recommendation Algorithm included in this repository:\",\n",
    "#       \"![](docs/system-diagram.png)\\n\\nThese are the main components of the Recommendation Algorithm included in this repository:\",\n",
    "#       \"| Type | Component | Description |\\n|------------|------------|------------|\\n| Feature | [SimClusters](src/scala/com/twitter/simclusters_v2/README.md) | Community detection and sparse embeddings into those communities. |\\n|         | [TwHIN](https://github.com/twitter/the-algorithm-ml/blob/main/projects/twhin/README.md) | Dense knowledge graph embeddings for Users and Tweets. |\\n|         | [trust-and-safety-models](trust_and_safety_models/README.md) | Models for detecting NSFW or abusive content. |\\n|         | [real-graph](src/scala/com/twitter/interaction_graph/README.md) | Model to predict the likelihood of a Twitter User interacting with another User. |\\n|         | [tweepcred](src/scala/com/twitter/graph/batch/job/tweepcred/README) | Page-Rank algorithm for calculating Twitter User reputation. |\\n|         | [recos-injector](recos-injector/README.md) | Streaming event processor for building input streams for [GraphJet](https://github.com/twitter/GraphJet) based services. |\\n|         | [graph-feature-service](graph-feature-service/README.md) | Serves graph features for a directed pair of Users (e.g. how many of User A's following liked Tweets from User B). |\\n| Candidate Source | [search-index](src/java/com/twitter/search/README.md) | Find and rank In-Network Tweets. ~50% of Tweets come from this candidate source. |\\n|                  | [cr-mixer](cr-mixer/README.md) | Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services. |\\n|                  | [user-tweet-entity-graph](src/scala/com/twitter/recos/user_tweet_entity_graph/README.md) (UTEG)| Maintains an in memory User to Tweet interaction graph, and finds candidates based on traversals of this graph. This is built on the [GraphJet](https://github.com/twitter/GraphJet) framework. Several other GraphJet based features and candidate sources are located [here](src/scala/com/twitter/recos). |\\n|                  | [follow-recommendation-service](follow-recommendations-service/README.md) (FRS)| Provides Users with recommendations for accounts to follow, and Tweets from those accounts. |\\n| Ranking | [light-ranker](src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/README.md) | Light Ranker model used by search index (Earlybird) to rank Tweets. |\\n|         | [heavy-ranker](https://github.com/twitter/the-algorithm-ml/blob/main/projects/home/recap/README.md) | Neural network for ranking candidate tweets. One of the main signals used to select timeline Tweets post candidate sourcing. |\\n| Tweet mixing & filtering | [home-mixer](home-mixer/README.md) | Main service used to construct and serve the Home Timeline. Built on [product-mixer](product-mixer/README.md). |\\n|                          | [visibility-filters](visibilitylib/README.md) | Responsible for filtering Twitter content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking. |\\n|                          | [timelineranker](timelineranker/README.md) | Legacy service which provides relevance-scored tweets from the Earlybird Search Index and UTEG service. |\\n| Software framework | [navi](navi/README.md) | High performance, machine learning model serving written in Rust. |\\n|                    | [product-mixer](product-mixer/README.md) | Software framework for building feeds of content. |\\n|                    | [twml](twml/README.md) | Legacy machine learning framework built on TensorFlow v1. |\",\n",
    "#       \"We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file.\\n\\n## Contributing\",\n",
    "#       \"We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file.\\n\\n## Contributing\\n\\nWe invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official [bug bounty program](https://hackerone.com/twitter) through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better Twitter.\\n\\nRead our blog on the open source initiative [here](https://blog.twitter.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter).\"\n",
    "#     ],\n",
    "#     \"score\": [\n",
    "#       22.843185424804688,\n",
    "#       22.83962631225586,\n",
    "#       22.835460662841797,\n",
    "#       22.83342170715332,\n",
    "#       22.832916259765625\n",
    "#     ]\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b98abd-6386-48c1-a63f-941f91410c92",
   "metadata": {},
   "source": [
    "### Migrating Datasets to the Tensor Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda430f9-fe83-4d05-96e7-48610be2e60b",
   "metadata": {},
   "source": [
    "#### Migrate existing Deep Lake datasets to the Tensor Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a31d98d6-e6fd-4173-ac1b-0105be1c7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets are created in the Tensor Database by specifying the dest  during dataset creation.\n",
    "# If datasets are currently stored locally, in your cloud, or in non-database Activeloop storage,\n",
    "#   they can be migrated to the Tensor Database using.\n",
    "\n",
    "# dest = \"hub://<org_id>/<dataset_name>\" and runtime = {\"tensor_db\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8d22ca-20f4-4e70-a0b4-c5497e7c56cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import deeplake\n",
    "\n",
    "# ds_tensor_db = deeplake.deepcopy(src = <current_path>, \n",
    "#                                  dest = \"hub://<org_id>/<dataset_name>\", \n",
    "#                                  runtime = {\"tensor_db\": True}, \n",
    "#                                  src_creds = {<creds_dict>}, # Only necessary if src is in your cloud\n",
    "#                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1eaed7-66e2-4021-9f1f-bee2b8c7d056",
   "metadata": {},
   "source": [
    "## REST API (EXAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3549a03-c498-4e50-8715-f8e8e3ff0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22090bd-6579-4711-b153-c72e0e98dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens should be set in environmental variables.\n",
    "ACTIVELOOP_TOKEN = os.environ['ACTIVELOOP_TOKEN']\n",
    "DATASET_PATH = 'hub://activeloop/twitter-algorithm'\n",
    "ENDPOINT_URL = 'https://app.activeloop.ai/api/query/v1'\n",
    "SEARCH_TERM = 'What do the trust and safety models do?'\n",
    "# os.environ['OPENAI_API_KEY'] OPEN AI TOKEN should also exist in env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eab0c01a-821c-4ff8-acb5-b3dc78333ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The headers contains the user token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ACTIVELOOP_TOKEN}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8218b25b-c9f6-4f4c-9650-5c2ed697e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the search term\n",
    "\n",
    "# embedding = openai.Embedding.create(input=SEARCH_TERM, model=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n",
    "embedding = openai.embeddings.create(input=SEARCH_TERM, model=\"text-embedding-ada-002\").data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b8fae2-3b36-400c-bd9f-9639691f4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the embedding array or list as a string, so it can be passed in the REST API request.\n",
    "embedding_string = \",\".join([str(item) for item in embedding])\n",
    "\n",
    "# Create the query using TQL\n",
    "# query = f\"select * from (select text, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score from \\\"{dataset_path}\\\") order by score desc limit 5\"\n",
    "query = f\"select * from (select text, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score from \\\"{DATASET_PATH}\\\") order by score desc limit 5\"\n",
    "          \n",
    "# Submit the request\n",
    "response = requests.post(ENDPOINT_URL, json={\"query\": query}, headers=headers)\n",
    "\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53eecb72-603b-420c-8591-c23a59163340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful.\n",
      "['text', 'score']\n"
     ]
    }
   ],
   "source": [
    "# print(data)\n",
    "print(data[\"description\"])\n",
    "print(data[\"tensors\"])\n",
    "# print(data[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "542ef652-9253-4ea5-8e35-383bf8e2d6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8365592956542969\n"
     ]
    }
   ],
   "source": [
    "print(data[\"data\"][0][\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09e720b0-8f10-4be0-a1d5-e3a37d493695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust and Safety Models\n",
      "=======================\n",
      "\n",
      "We decided to open source the training code of the following models:\n",
      "- pNSFWMedia: Model to detect tweets with NSFW images. This includes adult and porn content.\n",
      "- pNSFWText: Model to detect tweets with NSFW text, adult/sexual topics.\n",
      "- pToxicity: Model to detect toxic tweets. Toxicity includes marginal content like insults and certain types of harassment. Toxic content does not violate Twitter's terms of service.\n",
      "- pAbuse: Model to detect abusive content. This includes violations of Twitter's terms of service, including hate speech, targeted harassment and abusive behavior.\n",
      "\n",
      "We have several more models and rules that we are not going to open source at this time because of the adversarial nature of this area. The team is considering open sourcing more models going forward and will keep the community posted accordingly.\n"
     ]
    }
   ],
   "source": [
    "print(data[\"data\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62e6342f-cbe5-4349-8173-5ffdcb9beb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Query successful.', 'tensors': ['text', 'score'], 'data': [{'text': \"Trust and Safety Models\\n=======================\\n\\nWe decided to open source the training code of the following models:\\n- pNSFWMedia: Model to detect tweets with NSFW images. This includes adult and porn content.\\n- pNSFWText: Model to detect tweets with NSFW text, adult/sexual topics.\\n- pToxicity: Model to detect toxic tweets. Toxicity includes marginal content like insults and certain types of harassment. Toxic content does not violate Twitter's terms of service.\\n- pAbuse: Model to detect abusive content. This includes violations of Twitter's terms of service, including hate speech, targeted harassment and abusive behavior.\\n\\nWe have several more models and rules that we are not going to open source at this time because of the adversarial nature of this area. The team is considering open sourcing more models going forward and will keep the community posted accordingly.\", 'score': 0.8365592956542969}, {'text': 'private lazy val thriftToModelMap: Map[ThriftSafetyLevel, SafetyLevel] = Map(\\n    ThriftSafetyLevel.AccessInternalPromotedContent -> AccessInternalPromotedContent,\\n    ThriftSafetyLevel.AdsBusinessSettings -> AdsBusinessSettings,\\n    ThriftSafetyLevel.AdsCampaign -> AdsCampaign,\\n    ThriftSafetyLevel.AdsManager -> AdsManager,\\n    ThriftSafetyLevel.AdsReportingDashboard -> AdsReportingDashboard,\\n    ThriftSafetyLevel.AllSubscribedLists -> AllSubscribedLists,\\n    ThriftSafetyLevel.Appeals -> Appeals,\\n    ThriftSafetyLevel.ArticleTweetTimeline -> ArticleTweetTimeline,\\n    ThriftSafetyLevel.BaseQig -> BaseQig,\\n    ThriftSafetyLevel.BirdwatchNoteAuthor -> BirdwatchNoteAuthor,\\n    ThriftSafetyLevel.BirdwatchNoteTweetsTimeline -> BirdwatchNoteTweetsTimeline,\\n    ThriftSafetyLevel.BirdwatchNeedsYourHelpNotifications -> BirdwatchNeedsYourHelpNotifications,\\n    ThriftSafetyLevel.BlockMuteUsersTimeline -> BlockMuteUsersTimeline,\\n    ThriftSafetyLevel.BrandSafety -> BrandSafety,\\n    ThriftSafetyLevel.CardPollVoting -> CardPollVoting,\\n    ThriftSafetyLevel.CardsService -> CardsService,\\n    ThriftSafetyLevel.Communities -> Communities,\\n    ThriftSafetyLevel.ContentControlToolInstall -> ContentControlToolInstall,\\n    ThriftSafetyLevel.ConversationFocalPrehydration -> ConversationFocalPrehydration,\\n    ThriftSafetyLevel.ConversationFocalTweet -> ConversationFocalTweet,\\n    ThriftSafetyLevel.ConversationInjectedTweet -> ConversationInjectedTweet,\\n    ThriftSafetyLevel.ConversationReply -> ConversationReply,\\n    ThriftSafetyLevel.CuratedTrendsRepresentativeTweet -> CuratedTrendsRepresentativeTweet,\\n    ThriftSafetyLevel.CurationPolicyViolations -> CurationPolicyViolations,\\n    ThriftSafetyLevel.DevPlatformGetListTweets -> DevPlatformGetListTweets,\\n    ThriftSafetyLevel.DesFollowingAndFollowersUserList -> DesFollowingAndFollowersUserList,\\n    ThriftSafetyLevel.DesHomeTimeline -> DesHomeTimeline,\\n    ThriftSafetyLevel.DesQuoteTweetTimeline -> DesQuoteTweetTimeline,\\n    ThriftSafetyLevel.DesRealtime -> DesRealtime,\\n    ThriftSafetyLevel.DesRealtimeSpamEnrichment -> DesRealtimeSpamEnrichment,\\n    ThriftSafetyLevel.DesRealtimeTweetFilter -> DesRealtimeTweetFilter,\\n    ThriftSafetyLevel.DesRetweetingUsers -> DesRetweetingUsers,\\n    ThriftSafetyLevel.DesTweetDetail -> DesTweetDetail,\\n    ThriftSafetyLevel.DesTweetLikingUsers -> DesTweetLikingUsers,\\n    ThriftSafetyLevel.DesUserBookmarks -> DesUserBookmarks,\\n    ThriftSafetyLevel.DesUserLikedTweets -> DesUserLikedTweets,\\n    ThriftSafetyLevel.DesUserMentions -> DesUserMentions,\\n    ThriftSafetyLevel.DesUserTweets -> DesUserTweets,\\n    ThriftSafetyLevel.DevPlatformComplianceStream -> DevPlatformComplianceStream,\\n    ThriftSafetyLevel.DirectMessages -> DirectMessages,\\n    ThriftSafetyLevel.DirectMessagesConversationList -> DirectMessagesConversationList,\\n    ThriftSafetyLevel.DirectMessagesConversationTimeline -> DirectMessagesConversationTimeline,\\n    ThriftSafetyLevel.DirectMessagesInbox -> DirectMessagesInbox,\\n    ThriftSafetyLevel.DirectMessagesMutedUsers -> DirectMessagesMutedUsers,\\n    ThriftSafetyLevel.DirectMessagesPinned -> DirectMessagesPinned,\\n    ThriftSafetyLevel.DirectMessagesSearch -> DirectMessagesSearch,\\n    ThriftSafetyLevel.EditHistoryTimeline -> EditHistoryTimeline,\\n    ThriftSafetyLevel.ElevatedQuoteTweetTimeline -> ElevatedQuoteTweetTimeline,\\n    ThriftSafetyLevel.EmbeddedTweet -> EmbeddedTweet,\\n    ThriftSafetyLevel.EmbedsPublicInterestNotice -> EmbedsPublicInterestNotice,\\n    ThriftSafetyLevel.EmbedTweetMarkup -> EmbedTweetMarkup,\\n    ThriftSafetyLevel.ExploreRecommendations -> ExploreRecommendations,\\n    ThriftSafetyLevel.WritePathLimitedActionsEnforcement -> WritePathLimitedActionsEnforcement,\\n    ThriftSafetyLevel.FilterAll -> FilterAll,\\n    ThriftSafetyLevel.FilterAllPlaceholder -> FilterAllPlaceholder,\\n    ThriftSafetyLevel.FilterDefault -> FilterDefault,\\n    ThriftSafetyLevel.FilterNone -> FilterNone,\\n    ThriftSafetyLevel.FollowedTopicsTimeline -> FollowedTopicsTimeline,', 'score': 0.7695692777633667}, {'text': 'private lazy val modelToThriftMap: Map[SafetyLevel, ThriftSafetyLevel] =\\n    for ((k, v) <- thriftToModelMap) yield (v, k)', 'score': 0.7662665247917175}, {'text': 'private lazy val thriftToModelMap: Map[s.SpaceSafetyLabelType, SpaceSafetyLabelType] = Map(\\n    s.SpaceSafetyLabelType.DoNotAmplify -> DoNotAmplify,\\n    s.SpaceSafetyLabelType.CoordinatedHarmfulActivityHighRecall -> CoordinatedHarmfulActivityHighRecall,\\n    s.SpaceSafetyLabelType.UntrustedUrl -> UntrustedUrl,\\n    s.SpaceSafetyLabelType.MisleadingHighRecall -> MisleadingHighRecall,\\n    s.SpaceSafetyLabelType.NsfwHighPrecision -> NsfwHighPrecision,\\n    s.SpaceSafetyLabelType.NsfwHighRecall -> NsfwHighRecall,\\n    s.SpaceSafetyLabelType.CivicIntegrityMisinfo -> CivicIntegrityMisinfo,\\n    s.SpaceSafetyLabelType.MedicalMisinfo -> MedicalMisinfo,\\n    s.SpaceSafetyLabelType.GenericMisinfo -> GenericMisinfo,\\n    s.SpaceSafetyLabelType.DmcaWithheld -> DmcaWithheld,\\n    s.SpaceSafetyLabelType.HatefulHighRecall -> HatefulHighRecall,\\n    s.SpaceSafetyLabelType.ViolenceHighRecall -> ViolenceHighRecall,\\n    s.SpaceSafetyLabelType.HighToxicityModelScore -> HighToxicityModelScore,\\n    s.SpaceSafetyLabelType.DeprecatedSpaceSafetyLabel14 -> Deprecated,\\n    s.SpaceSafetyLabelType.DeprecatedSpaceSafetyLabel15 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved16 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved17 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved18 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved19 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved20 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved21 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved22 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved23 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved24 -> Deprecated,\\n    s.SpaceSafetyLabelType.Reserved25 -> Deprecated,\\n  )', 'score': 0.7577966451644897}, {'text': 'In summary, the SALSA Candidate Source provides an account expansion based on the SALSA PYMK algorithm, utilizing a bipartite graph with personalized random walks to identify the most relevant and interesting recommendations for the user.', 'score': 0.7566139698028564}]}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
