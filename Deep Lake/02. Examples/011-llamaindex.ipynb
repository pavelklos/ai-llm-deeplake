{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (RAG)\n",
    "- [RAG](https://docs.activeloop.ai/examples/rag)\n",
    "  - [RAG Quickstart](https://docs.activeloop.ai/examples/rag/quickstart)\n",
    "  - [RAG Tutorials](https://docs.activeloop.ai/examples/rag/tutorials)\n",
    "    - [Vector Store Basics](https://docs.activeloop.ai/examples/rag/tutorials/vector-store-basics)\n",
    "    - [Vector Search Options](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options)\n",
    "      - [LangChain API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/langchain-api)\n",
    "      - [Deep Lake Vector Store API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/vector-store-api)\n",
    "      - [Managed Database REST API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/rest-api)\n",
    "    - [Customizing Your Vector Store](https://docs.activeloop.ai/examples/rag/tutorials/step-4-customizing-vector-stores)\n",
    "    - [Image Similarity Search](https://docs.activeloop.ai/examples/rag/tutorials/image-similarity-search)\n",
    "    - [Improving Search Accuracy using Deep Memory](https://docs.activeloop.ai/examples/rag/tutorials/deepmemory)\n",
    "  - [LangChain Integration](https://docs.activeloop.ai/examples/rag/langchain-integration)\n",
    "  - [**LlamaIndex Integration**](https://docs.activeloop.ai/examples/rag/llamaindex-integration)\n",
    "  - [Managed Tensor Database](https://docs.activeloop.ai/examples/rag/managed-database)\n",
    "    - [REST API](https://docs.activeloop.ai/examples/rag/managed-database/rest-api)\n",
    "    - [Migrating Datasets to the Tensor Database](https://docs.activeloop.ai/examples/rag/managed-database/migrating-datasets-to-the-tensor-database)\n",
    "  - [Deep Memory](https://docs.activeloop.ai/examples/rag/deep-memory)\n",
    "    - [How it Works](https://docs.activeloop.ai/examples/rag/deep-memory/how-it-works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9134e12-66df-4b48-915d-a3b9f5e1c550",
   "metadata": {},
   "source": [
    "## RAG (LlamaIndex Integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96007e-3a02-4498-8127-e30e1447c543",
   "metadata": {},
   "source": [
    "### Use Deep Lake as a Vector Store in LlamaIndex\n",
    "*Deep Lake can be used as a VectorStore in LlamaIndex for building Apps that require filtering and vector search. In this tutorial we will show how to create a Deep Lake Vector Store in LangChain and use it to build a Q&A App about the Twitter OSS recommendation algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e5667-baa8-403b-b4e0-478f93a741b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install llama-index-vector-stores-deeplake\n",
    "# !pip3 install langchain llama-index deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4a49f9-28d0-4df6-8275-6016b3911d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-vector-stores-deeplake\n",
    "# !pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370e3be-21ee-4be5-8057-13eb9514d93f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb062e7-e7da-4b50-aacb-d9669e05e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5996ee04-9d9f-46fd-855b-a11deead1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af670a7f-5c7c-46a1-b25c-038fd6a2147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Twitter OSS recommendation algorithm\n",
    "\n",
    "# !git clone https://github.com/twitter/the-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06eee1b-a33d-4556-b7c6-4f25b8290a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a local path to the files and add a reader for processing and chunking them\n",
    "\n",
    "# repo_path = '/the-algorithm'\n",
    "# repo_path = './the-algorithm'\n",
    "repo_path = './the-algorithm/twml/twml/layers'\n",
    "\n",
    "documents = SimpleDirectoryReader(repo_path, recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb47962b-acbd-4df2-96ad-24440755fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf5044-b172-4941-b72a-c2c8a330afbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Creating the Deep Lake Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b600c13-ba1c-4eb4-a504-d368c02a8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Create an empty Deep Lake Vector Store using a specified path\n",
    "\n",
    "# dataset_path = 'hub://<org-id>/twitter_algorithm'\n",
    "dataset_path = 'hub://pavelkloscz/twitter_algorithm_twml_2'  # [twml] subdirectory of this github repo\n",
    "vector_store = DeepLakeVectorStore(dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8afd36-f4e0-4aa2-a7e4-5e1b80168a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Lake Vector Store has 4 tensors including the text, embedding, ids, and  metadata which includes the filename of the text\n",
    "\n",
    " #  tensor      htype     shape    dtype  compression\n",
    " #  -------    -------   -------  -------  ------- \n",
    " #   text       text      (0,)      str     None   \n",
    " # metadata     json      (0,)      str     None   \n",
    " # embedding  embedding   (0,)    float32   None   \n",
    " #    id        text      (0,)      str     None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6c2a565-982b-4eae-81ef-31d9be227ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:01<00:00, 21.35it/s]\n",
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://pavelkloscz/twitter_algorithm_twml_2', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (24, 1)      str     None   \n",
      " metadata     json      (24, 1)      str     None   \n",
      " embedding  embedding  (24, 1536)  float32   None   \n",
      "    id        text      (24, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# Create a LlamaIndex StorageContext and VectorStoreIndex, and use the from_documents() method to populate\n",
    "#   the Vector Store with data. This step takes several minutes because of the time to embed the text\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context,\n",
    ")\n",
    "\n",
    "# [OUTPUT] Vector Store has 8286 rows of data\n",
    " #  tensor      htype       shape       dtype  compression\n",
    " #  -------    -------     -------     -------  ------- \n",
    " #   text       text      (8262, 1)      str     None   \n",
    " # metadata     json      (8262, 1)      str     None   \n",
    " # embedding  embedding  (8262, 1536)  float32   None   \n",
    " #    id        text      (8262, 1)      str     None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ee8c39-faeb-475e-baab-ec8a7a51e353",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Use the Vector Store in a Q&A App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdd82a3-a3f8-4d72-9e8d-60f985c9486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://pavelkloscz/twitter_algorithm_twml_2 already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# Use the VectorStore in Q&A app, where the embeddings will be used to filter relevant documents (texts)\n",
    "#   that are fed into an LLM in order to answer a question.\n",
    "# If we were on another machine, we would load the existing Vector Store without re-ingesting the data\n",
    "\n",
    "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, read_only=True)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea2463e3-ba27-4e4f-8fb4-9f70230f9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LlamaIndex query engine and run a query\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70155e77-4ffb-472a-b871-b0664c7ff4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python\n"
     ]
    }
   ],
   "source": [
    "# response = query_engine.query(\"What programming language is most of the SimClusters written in?\")\n",
    "response = query_engine.query(\"What programming language is most of the Batch Prediction written in?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761bb70f-559e-434c-b019-80c12ba81306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of the TWML (TensorFlow Wrapper for Machine Learning) code is written in Python.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What programming language is most of the TWML written in?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
