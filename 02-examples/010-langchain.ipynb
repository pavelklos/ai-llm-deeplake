{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (RAG)\n",
    "- [RAG](https://docs.activeloop.ai/examples/rag)\n",
    "  - [RAG Quickstart](https://docs.activeloop.ai/examples/rag/quickstart)\n",
    "  - [RAG Tutorials](https://docs.activeloop.ai/examples/rag/tutorials)\n",
    "    - [Vector Store Basics](https://docs.activeloop.ai/examples/rag/tutorials/vector-store-basics)\n",
    "    - [Vector Search Options](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options)\n",
    "      - [LangChain API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/langchain-api)\n",
    "      - [Deep Lake Vector Store API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/vector-store-api)\n",
    "      - [Managed Database REST API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/rest-api)\n",
    "    - [Customizing Your Vector Store](https://docs.activeloop.ai/examples/rag/tutorials/step-4-customizing-vector-stores)\n",
    "    - [Image Similarity Search](https://docs.activeloop.ai/examples/rag/tutorials/image-similarity-search)\n",
    "    - [Improving Search Accuracy using Deep Memory](https://docs.activeloop.ai/examples/rag/tutorials/deepmemory)\n",
    "  - [**LangChain Integration**](https://docs.activeloop.ai/examples/rag/langchain-integration)\n",
    "  - [LlamaIndex Integration](https://docs.activeloop.ai/examples/rag/llamaindex-integration)\n",
    "  - [Managed Tensor Database](https://docs.activeloop.ai/examples/rag/managed-database)\n",
    "    - [REST API](https://docs.activeloop.ai/examples/rag/managed-database/rest-api)\n",
    "    - [Migrating Datasets to the Tensor Database](https://docs.activeloop.ai/examples/rag/managed-database/migrating-datasets-to-the-tensor-database)\n",
    "  - [Deep Memory](https://docs.activeloop.ai/examples/rag/deep-memory)\n",
    "    - [How it Works](https://docs.activeloop.ai/examples/rag/deep-memory/how-it-works)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9134e12-66df-4b48-915d-a3b9f5e1c550",
   "metadata": {},
   "source": [
    "## RAG (LangChain Integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68283fa7-7c37-4fad-98da-d8583bba93d1",
   "metadata": {},
   "source": [
    "### Use Deep Lake as a Vector Store in LangChain\n",
    "*Deep Lake can be used as a VectorStore in LangChain for building Apps that require filtering and vector search. In this tutorial we will show how to create a Deep Lake Vector Store in LangChain and use it to build a Q&A App about the Twitter OSS recommendation algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91008277-dc8a-4f46-90af-a7dec91006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f0bd42-f7c1-4e76-a8bf-c56f63cf1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9f777-57cc-41a1-83e5-465c68380295",
   "metadata": {},
   "source": [
    "#### Downloading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a9a252-e5fd-4d80-ac8d-9aaf0947bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.14) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain.vectorstores import DeepLake\n",
    "from langchain_community.vectorstores import DeepLake\n",
    "# from langchain_deeplake.vectorstores import DeeplakeVectorStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1da134b-9b60-4b8c-b4c0-b4f55ccc79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd24cbd-4a89-4b11-b4d9-3d0aa5ccef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Twitter OSS recommendation algorithm\n",
    "\n",
    "# !git clone https://github.com/twitter/the-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b4dfcf-ff4d-447e-86ee-35e40b29ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_prediction_tensor_writer.py\n",
      "batch_prediction_writer.py\n",
      "data_record_tensor_writer.py\n",
      "full_dense.py\n",
      "full_sparse.py\n",
      "isotonic.py\n",
      "layer.py\n",
      "mdl.py\n",
      "partition.py\n",
      "percentile_discretizer.py\n",
      "sequential.py\n",
      "sparse_max_norm.py\n",
      "stitch.py\n",
      "__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Load all the files from the repo into a list\n",
    "\n",
    "repo_path = '/the-algorithm'\n",
    "# repo_path = './the-algorithm'\n",
    "repo_path = './the-algorithm/twml/twml/layers'\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(repo_path):\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "            print(file)  # TODO: COMMENT\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf1413d-2ebb-444e-852a-600af2ab5bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadc7e83-e8b4-4829-b640-88571bd7bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1684, which is longer than the specified 1000\n",
      "Created a chunk of size 1760, which is longer than the specified 1000\n",
      "Created a chunk of size 1157, which is longer than the specified 1000\n",
      "Created a chunk of size 2504, which is longer than the specified 1000\n",
      "Created a chunk of size 1427, which is longer than the specified 1000\n",
      "Created a chunk of size 1438, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# [Note on chunking text files]\n",
    "# - Text files are typically split into chunks before creating embeddings.\n",
    "# - In general, more chunks increases the relevancy of data that is fed into the language model,\n",
    "#   since granular data can be selected with higher precision.\n",
    "# - However, since an embedding will be created for each chunk, more chunks increase the computational complexity.\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a6d6bf-d528-47f1-b164-b21c6401a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(type(texts))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44553564-3a92-4047-8203-5df551b5fe56",
   "metadata": {},
   "source": [
    "**Chunks in the above context should not be confused with Deep Lake chunks!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb75b11-b846-4c8c-8872-5299186d05cb",
   "metadata": {},
   "source": [
    "#### Creating the Deep Lake Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e0adb2-3378-4088-a6af-13b451cf2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = 'hub://<org-id>/twitter_algorithm'\n",
    "dataset_path = 'hub://pavelkloscz/twitter_algorithm_twml'  # [twml] subdirectory of this github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e421655-106b-44fa-b05e-08cb61b8afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an OpenAI algorithm for creating the embeddings, and create the VectorStore.\n",
    "# This process creates an embedding for each element in the texts lists and stores it in Deep Lake format at the specified path\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce7b2af-7b43-4102-8b5d-058078cf19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 86 embeddings in 1 batches of size 86:: 100%|███████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://pavelkloscz/twitter_algorithm_twml', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (86, 1)      str     None   \n",
      " metadata     json      (86, 1)      str     None   \n",
      " embedding  embedding  (86, 1536)  float32   None   \n",
      "    id        text      (86, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake.from_documents(texts, embeddings, dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcee454-b29a-4a25-b917-cce6d0ad8335",
   "metadata": {},
   "source": [
    "**Deep Lake Vector Store has 4 tensors including the text, embedding, ids, and  metadata.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ebca3-5921-427d-9b7c-e2060b06f710",
   "metadata": {},
   "source": [
    "#### Use the Vector Store in a Q&A App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f9eee2-9487-4407-bdb8-dcea4dcf65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_27584\\547977038.py:5: LangChainDeprecationWarning: This class is deprecated and will be removed in a future version. You can swap to using the `DeeplakeVectorStore` implementation in `langchain-deeplake`. Please do not submit further PRs to this class.See <https://github.com/activeloopai/langchain-deeplake>\n",
      "  db = DeepLake(dataset_path=dataset_path, read_only=True, embedding=embeddings)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://pavelkloscz/twitter_algorithm_twml already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# Use the VectorStore in Q&A app, where the embeddings will be used to filter relevant documents (texts)\n",
    "#   that are fed into an LLM in order to answer a question.\n",
    "# If we were on another machine, we would load the existing Vector Store without recalculating the embeddings.\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, read_only=True, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68152d6c-7730-4c3d-9a3f-9aec6a0535af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever object and specify the search parameters\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['k'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8ba2325-02d1-412f-86cb-25f6b36edcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RetrievalQA chain in LangChain and run it\n",
    "\n",
    "# model = ChatOpenAI(model='gpt-4') # 'gpt-3.5-turbo',\n",
    "model = ChatOpenAI(model=MODEL_GPT) # 'gpt-3.5-turbo',\n",
    "qa = RetrievalQA.from_llm(model, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ef47bd-4580-48d0-b384-e4f624d6ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What programming language is most of the Batch Prediction written in?',\n",
       " 'result': 'Most of the Batch Prediction code is written in Python.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qa.run('What programming language is most of the SimClusters written in?')\n",
    "# qa.invoke('What programming language is most of the SimClusters written in?')\n",
    "qa.invoke('What programming language is most of the Batch Prediction written in?')  ## batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a845fbf-03da-4b37-b557-7a73c6b802bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What programming language is most of the TWML written in?',\n",
       " 'result': 'Most of the TWML is written in Python, as indicated by the use of Python syntax and libraries such as TensorFlow in the provided contexts.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke('What programming language is most of the TWML written in?')  ## twml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcdae6c-f66b-48ee-b8c7-c261d0187540",
   "metadata": {},
   "source": [
    "**We can tune k in the retriever depending on whether the prompt exceeds the model's token limit.**<br>\n",
    "**Higher k increases the accuracy by including more data in the prompt.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36724224-be33-4cc5-97f0-a1659d20715c",
   "metadata": {},
   "source": [
    "#### Adding data to to an existing Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f171a3d3-b1fe-49cc-8bfe-30f5527bec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://pavelkloscz/twitter_algorithm_twml already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# Data can be added to an existing Vector Store by loading it using its path and adding documents or texts\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding=embeddings)\n",
    "\n",
    "# Don't run this here in order to avoid data duplication\n",
    "# db.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5c100-a373-4ba3-8baa-6212f7eb3f66",
   "metadata": {},
   "source": [
    "#### Adding Hybrid Search to the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99f77a76-d275-400e-9e0e-168eaa3af7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since embeddings search can be computationally expensive, you can simplify the search by filtering out data using an\n",
    "#   explicit search on top of the embeddings search. Suppose we want to answer to a question related to the trust and safety models.\n",
    "# We can filter the filenames (source) in the metadata using a custom function that is added to the retriever\n",
    "def filter(deeplake_sample):\n",
    "    return 'trust_and_safety_models' in deeplake_sample['metadata'].data()['value']['source']\n",
    "\n",
    "retriever.search_kwargs['filter'] = filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcef1f47-d0f2-4c4f-9435-3c8bfda82ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 86/86 [00:00<00:00, 145.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What do the trust and safety models do?',\n",
       " 'result': 'Trust and safety models are designed to protect users and maintain a safe environment on platforms, typically in the context of online services and communities. They help identify, prevent, and address harmful behaviors such as harassment, abuse, misinformation, and fraud. These models often include the use of algorithms and human moderation to monitor user interactions, enforce community guidelines, and ensure compliance with legal and ethical standards. Ultimately, their goal is to create a secure and positive experience for all users.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = RetrievalQA.from_llm(model, retriever=retriever)\n",
    "\n",
    "# qa.run(\"What do the trust and safety models do?\")\n",
    "qa.invoke(\"What do the trust and safety models do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d78425ca-8f66-499a-b754-f02081b79967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters can also be specified as a dictionary.\n",
    "# For example, if the metadata tensor had a key year, we can filter based on that key using\n",
    "\n",
    "# retriever.search_kwargs['filter'] = {\"metadata\": {\"year\": 2020}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aacf36-8eb4-406d-b144-e300775799fd",
   "metadata": {},
   "source": [
    "#### Using Deep Lake in Applications that Require Concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ba85b27-6155-443f-bb4d-32fb47e1fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For applications that require writing of data concurrently, users should set up a lock system to queue\n",
    "#   the write operations and prevent multiple clients from writing to the Deep Lake Vector Store at the same time.\n",
    "# This can be done with a few lines of code in the example below\n",
    "\n",
    "# [Concurrency Using Zookeeper Locks]\n",
    "# - https://docs.activeloop.ai/technical-details/best-practices/concurrent-writes/concurrency-using-zookeeper-locks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb0f40-a15e-4fff-a7e0-6da3e3284ad5",
   "metadata": {},
   "source": [
    "#### Accessing the Low Level Deep Lake API (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f61dfc9-f9d9-4e84-9035-4f6176d1123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://pavelkloscz/twitter_algorithm_twml already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# When using a Deep Lake Vector Store in LangChain, the underlying Vector Store and its low-level Deep Lake dataset can be accessed via\n",
    "\n",
    "# LangChain Vector Store\n",
    "db = DeepLake(dataset_path=dataset_path)\n",
    "\n",
    "# Deep Lake Vector Store object\n",
    "ds = db.vectorstore\n",
    "\n",
    "# Deep Lake Dataset object\n",
    "ds = db.vectorstore.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca2206-4ad0-4258-9111-285e94a7dd32",
   "metadata": {},
   "source": [
    "#### SelfQueryRetriever with Deep Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0d1ca60-fa10-4df7-947d-443e97eb6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Lake supports the SelfQueryRetriever implementation in LangChain, which translates a user prompt into a metadata filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e3667c9-f71c-4086-bafe-6821c31ede0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section of the tutorial requires installation of additional packages\n",
    "\n",
    "# !pip install \"deeplake[enterprise]\" lark\n",
    "# !pip install lark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a16aea6c-55bd-452c-9dd6-47d999dd581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3ef6d18-a1f1-445e-b7e4-546c6b174e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create a Deep Lake Vector Store with relevant data using the documents below\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"rating\": 9.9,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"science fiction\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcd08045-39e8-4741-93bb-ddb8616206c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 6 embeddings in 1 batches of size 6:: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://pavelkloscz/self_query', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (6, 1)      str     None   \n",
      " metadata     json      (6, 1)      str     None   \n",
      " embedding  embedding  (6, 1536)  float32   None   \n",
      "    id        text      (6, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Since this feature uses Deep Lake's Tensor Query Language under the hood, the Vector Store must be stored in or connected to Deep Lake,\n",
    "#   which requires registration with Activeloop\n",
    "\n",
    "# org_id = <YOUR_ORG_ID> #By default, your username is an org_id\n",
    "org_id = \"pavelkloscz\" #By default, your username is an org_id\n",
    "dataset_path = f\"hub://{org_id}/self_query\"\n",
    "\n",
    "vectorstore = DeepLake.from_documents(\n",
    "    docs, embeddings, dataset_path = dataset_path, overwrite = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6225dd8-8ce3-4eba-99c6-8603626ae012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our retriever by providing information about the metadata fields that\n",
    "#   our documents support and a short description of the document contents\n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "# from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"genre\",\n",
    "        description=\"The genre of the movie\",\n",
    "        type=\"string or list[string]\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"year\",\n",
    "        description=\"The year the movie was released\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"director\",\n",
    "        description=\"The name of the movie director\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a62bbb97-b7d7-4897-b81f-fc88f464e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Brief summary of a movie\"\n",
    "# llm = OpenAI(temperature=0)\n",
    "llm = ChatOpenAI(model=MODEL_GPT, temperature=0)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm, vectorstore, document_content_description, metadata_field_info, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24127e91-196c-4935-b5c6-5ba959568071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction'}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
       " Document(metadata={'year': 1995, 'genre': 'animated'}, page_content='Toys come alive and have a blast doing so'),\n",
       " Document(metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'}, page_content='Three men walk into the Zone, three men walk out of the Zone'),\n",
       " Document(metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use our retriever\n",
    "\n",
    "# This example only specifies a relevant query\n",
    "retriever.get_relevant_documents(\"What are some movies about dinosaurs\")\n",
    "\n",
    "# [OUTPUT]\n",
    "# [Document(page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose', metadata={'year': 1993, 'rating': 7.7, 'genre': 'science fiction'}),\n",
    "#  Document(page_content='Toys come alive and have a blast doing so', metadata={'year': 1995, 'genre': 'animated'}),\n",
    "#  Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'}),\n",
    "#  Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63001644-ae58-4df9-918f-032f7735a5bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "User-specified TQL queries are not support for exec_option=python.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run a query to find movies that are above a certain ranking\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# This example only specifies a filter\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI want to watch a movie rated higher than 8.5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# [OUTPUT]\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# [Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}),\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#  Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'})]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    180\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:410\u001b[39m, in \u001b[36mBaseRetriever.get_relevant_documents\u001b[39m\u001b[34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_name:\n\u001b[32m    409\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m] = run_name\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m _kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain\\retrievers\\self_query\\base.py:307\u001b[39m, in \u001b[36mSelfQueryRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager)\u001b[39m\n\u001b[32m    305\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructured_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    306\u001b[39m new_query, search_kwargs = \u001b[38;5;28mself\u001b[39m._prepare_query(query, structured_query)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_docs_with_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain\\retrievers\\self_query\\base.py:281\u001b[39m, in \u001b[36mSelfQueryRetriever._get_docs_with_query\u001b[39m\u001b[34m(self, query, search_kwargs)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_docs_with_query\u001b[39m(\n\u001b[32m    279\u001b[39m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, search_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[32m    280\u001b[39m ) -> List[Document]:\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msearch_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:343\u001b[39m, in \u001b[36mVectorStore.search\u001b[39m\u001b[34m(self, query, search_type, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query using a specified search type.\u001b[39;00m\n\u001b[32m    328\u001b[39m \n\u001b[32m    329\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    340\u001b[39m \u001b[33;03m        \"mmr\", or \"similarity_score_threshold\".\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    345\u001b[39m     docs_and_similarities = \u001b[38;5;28mself\u001b[39m.similarity_search_with_relevance_scores(\n\u001b[32m    346\u001b[39m         query, **kwargs\n\u001b[32m    347\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:553\u001b[39m, in \u001b[36mDeepLake.similarity_search\u001b[39m\u001b[34m(self, query, k, **kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    495\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    496\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    497\u001b[39m     k: \u001b[38;5;28mint\u001b[39m = \u001b[32m4\u001b[39m,\n\u001b[32m    498\u001b[39m     **kwargs: Any,\n\u001b[32m    499\u001b[39m ) -> List[Document]:\n\u001b[32m    500\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[33;03m    Return docs most similar to query.\u001b[39;00m\n\u001b[32m    502\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m        List[Document]: List of Documents most similar to the query vector.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:415\u001b[39m, in \u001b[36mDeepLake._search\u001b[39m\u001b[34m(self, query, embedding, embedding_function, k, distance_metric, use_maximal_marginal_relevance, fetch_k, filter, return_score, exec_option, deep_memory, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtql\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mtql_query\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mtql\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_search_tql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtql\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_kwargs(kwargs, \u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedding_function:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:323\u001b[39m, in \u001b[36mDeepLake._search_tql\u001b[39m\u001b[34m(self, tql, exec_option, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_search_tql\u001b[39m(\n\u001b[32m    293\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    294\u001b[39m     tql: Optional[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    295\u001b[39m     exec_option: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    296\u001b[39m     **kwargs: Any,\n\u001b[32m    297\u001b[39m ) -> List[Document]:\n\u001b[32m    298\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Function for performing tql_search.\u001b[39;00m\n\u001b[32m    299\u001b[39m \n\u001b[32m    300\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    321\u001b[39m \u001b[33;03m        ValueError: If return_score is True but some condition is not met.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m     metadatas = result[\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    328\u001b[39m     texts = result[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deeplake_vectorstore.py:319\u001b[39m, in \u001b[36mVectorStore.search\u001b[39m\u001b[34m(self, embedding_data, embedding_function, embedding, k, distance_metric, query, filter, exec_option, embedding_tensor, return_tensors, return_view, deep_memory, return_tql)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deep_memory:\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DeepMemoryAccessError()\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deep_memory\\deep_memory.py:60\u001b[39m, in \u001b[36muse_deep_memory.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_deep_memory \u001b[38;5;129;01mand\u001b[39;00m distance_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     58\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdistance_metric\u001b[39m\u001b[33m\"\u001b[39m] = DEFAULT_DEEPMEMORY_DISTANCE_METRIC\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\dataset_handlers\\client_side_dataset_handler.py:202\u001b[39m, in \u001b[36mClientSideDH.search\u001b[39m\u001b[34m(self, embedding_data, embedding_function, embedding, k, distance_metric, query, filter, exec_option, embedding_tensor, return_tensors, return_view, deep_memory, return_tql)\u001b[39m\n\u001b[32m    198\u001b[39m     exec_option = \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    200\u001b[39m exec_option = exec_option \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exec_option\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_search_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_embedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m return_tensors = utils.parse_return_tensors(\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.dataset, return_tensors, embedding_tensor, return_view\n\u001b[32m    218\u001b[39m )\n\u001b[32m    219\u001b[39m embedding_function = utils.create_embedding_function(embedding_function)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\utils.py:243\u001b[39m, in \u001b[36mparse_search_args\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exec_option == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    244\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser-specified TQL queries are not support for exec_option=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexec_option\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m         )\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mfilter\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[31mValueError\u001b[39m: User-specified TQL queries are not support for exec_option=python."
     ]
    }
   ],
   "source": [
    "# Run a query to find movies that are above a certain ranking\n",
    "\n",
    "# This example only specifies a filter\n",
    "retriever.get_relevant_documents(\"I want to watch a movie rated higher than 8.5\")\n",
    "\n",
    "# [OUTPUT]\n",
    "# [Document(page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea', metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}),\n",
    "#  Document(page_content='Three men walk into the Zone, three men walk out of the Zone', metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12463889-c51f-4fe2-8b77-6db5a87fb0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://pavelkloscz/self_query already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# [GitHub Copilot]\n",
    "# How to Fix It\n",
    "# - Change your retriever configuration to use the tensor_db execution option, which supports TQL queries:\n",
    "\n",
    "# dataset_path = \"hub://your-org/your-dataset\"  # or \"path/to/local/dataset\"\n",
    "# Alternatively for a local testing dataset:\n",
    "# dataset_path = \"./my_deeplake_dataset\"\n",
    "\n",
    "# org_id = <YOUR_ORG_ID> #By default, your username is an org_id\n",
    "org_id = \"pavelkloscz\" #By default, your username is an org_id\n",
    "dataset_path = f\"hub://{org_id}/self_query\"\n",
    "\n",
    "# Create a vector store\n",
    "# vector_store = DeepLake(\n",
    "#     dataset_path=dataset_path,\n",
    "#     embedding_function=embeddings,\n",
    "#     read_only=False\n",
    "# )\n",
    "vector_store = DeepLake(dataset_path=dataset_path, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe73dc89-2b7f-4890-a84b-4b9e612f32e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityException",
     "evalue": "The managed query engine is only available for datasets stored in the managed database [runtime = {\"tensor_db\": True}].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnprocessableEntityException\u001b[39m              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m retriever = vector_store.as_retriever(\n\u001b[32m      3\u001b[39m     search_type=\u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     search_kwargs={\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     }\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Now you can run your query\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m results = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI want to watch a movie rated higher than 8.5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# If you're using a managed Deep Lake instance, the tensor_db execution option is required for TQL queries.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# For local datasets, you may need to ensure you're using the correct API methods compatible with your execution mode.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Alternatively, if you want to stick with the Python execution option, you should use a simple similarity search without TQL queries.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    180\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:410\u001b[39m, in \u001b[36mBaseRetriever.get_relevant_documents\u001b[39m\u001b[34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_name:\n\u001b[32m    409\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m] = run_name\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m _kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1074\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1072\u001b[39m _kwargs = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1076\u001b[39m     docs_and_similarities = (\n\u001b[32m   1077\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1078\u001b[39m             query, **_kwargs\n\u001b[32m   1079\u001b[39m         )\n\u001b[32m   1080\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:553\u001b[39m, in \u001b[36mDeepLake.similarity_search\u001b[39m\u001b[34m(self, query, k, **kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    495\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    496\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    497\u001b[39m     k: \u001b[38;5;28mint\u001b[39m = \u001b[32m4\u001b[39m,\n\u001b[32m    498\u001b[39m     **kwargs: Any,\n\u001b[32m    499\u001b[39m ) -> List[Document]:\n\u001b[32m    500\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[33;03m    Return docs most similar to query.\u001b[39;00m\n\u001b[32m    502\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m        List[Document]: List of Documents most similar to the query vector.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:451\u001b[39m, in \u001b[36mDeepLake._search\u001b[39m\u001b[34m(self, query, embedding, embedding_function, k, distance_metric, use_maximal_marginal_relevance, fetch_k, filter, return_score, exec_option, deep_memory, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embedding.shape) > \u001b[32m1\u001b[39m:\n\u001b[32m    449\u001b[39m         embedding = embedding[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membedding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_id_tensor_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m scores = result[\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    461\u001b[39m embeddings = result[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deeplake_vectorstore.py:319\u001b[39m, in \u001b[36mVectorStore.search\u001b[39m\u001b[34m(self, embedding_data, embedding_function, embedding, k, distance_metric, query, filter, exec_option, embedding_tensor, return_tensors, return_view, deep_memory, return_tql)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deep_memory:\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DeepMemoryAccessError()\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deep_memory\\deep_memory.py:60\u001b[39m, in \u001b[36muse_deep_memory.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_deep_memory \u001b[38;5;129;01mand\u001b[39;00m distance_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     58\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdistance_metric\u001b[39m\u001b[33m\"\u001b[39m] = DEFAULT_DEEPMEMORY_DISTANCE_METRIC\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\dataset_handlers\\client_side_dataset_handler.py:235\u001b[39m, in \u001b[36mClientSideDH.search\u001b[39m\u001b[34m(self, embedding_data, embedding_function, embedding, k, distance_metric, query, filter, exec_option, embedding_tensor, return_tensors, return_view, deep_memory, return_tql)\u001b[39m\n\u001b[32m    229\u001b[39m     distance_metric = index_maintenance.parse_index_distance_metric_from_params(\n\u001b[32m    230\u001b[39m         \u001b[38;5;28mself\u001b[39m.logger, \u001b[38;5;28mself\u001b[39m.distance_metric_index, distance_metric\n\u001b[32m    231\u001b[39m     )\n\u001b[32m    233\u001b[39m distance_metric = distance_metric \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_VECTORSTORE_DISTANCE_METRIC\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvector_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\vector_search.py:55\u001b[39m, in \u001b[36msearch\u001b[39m\u001b[34m(k, exec_option, deeplake_dataset, distance_metric, return_tensors, query, logger, filter, query_embedding, embedding_tensor, return_view, token, org_id, return_tql)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Searching function\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    query (Optional[str]) - TQL Query string for direct evaluation, without application of additional filters or vector search.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m \u001b[33;03m    return_tql (bool): Return TQL query used for the search. Defaults to False.\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m EXEC_OPTION_TO_SEARCH_TYPE: Dict[\u001b[38;5;28mstr\u001b[39m, Callable] = {\n\u001b[32m     51\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompute_engine\u001b[39m\u001b[33m\"\u001b[39m: vectorstore.indra_vector_search,\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m: vectorstore.python_vector_search,\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtensor_db\u001b[39m\u001b[33m\"\u001b[39m: vectorstore.indra_vector_search,\n\u001b[32m     54\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEXEC_OPTION_TO_SEARCH_TYPE\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\vector_search.py:40\u001b[39m, in \u001b[36mvector_search\u001b[39m\u001b[34m(query, query_emb, exec_option, dataset, logger, filter, embedding_tensor, distance_metric, k, return_tensors, return_view, token, org_id, return_tql)\u001b[39m\n\u001b[32m     32\u001b[39m utils.check_indra_installation(exec_option)\n\u001b[32m     34\u001b[39m view, tql_filter = filter_utils.attribute_based_filtering_tql(\n\u001b[32m     35\u001b[39m     view=dataset,\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mfilter\u001b[39m=\u001b[38;5;28mfilter\u001b[39m,\n\u001b[32m     37\u001b[39m     logger=logger,\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindra_search_algorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\search_algorithm.py:205\u001b[39m, in \u001b[36msearch\u001b[39m\u001b[34m(query_embedding, distance_metric, deeplake_dataset, k, tql_string, tql_filter, embedding_tensor, runtime, return_tensors, return_view, token, org_id, return_tql)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     searcher = SearchIndra(deeplake_dataset, org_id, token)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msearcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\search_algorithm.py:57\u001b[39m, in \u001b[36mSearchBasic.run\u001b[39m\u001b[34m(self, tql_string, return_view, return_tql, distance_metric, k, query_embedding, embedding_tensor, tql_filter, return_tensors)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     37\u001b[39m     tql_string: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     return_tensors: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     46\u001b[39m ):\n\u001b[32m     47\u001b[39m     tql_query = \u001b[38;5;28mself\u001b[39m._create_tql_string(\n\u001b[32m     48\u001b[39m         tql_string,\n\u001b[32m     49\u001b[39m         distance_metric,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m         return_tensors,\n\u001b[32m     55\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     view = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_view:\n\u001b[32m     63\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m view\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\search_algorithm.py:147\u001b[39m, in \u001b[36mSearchManaged._get_view\u001b[39m\u001b[34m(self, tql_query, runtime)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_view\u001b[39m(\u001b[38;5;28mself\u001b[39m, tql_query, runtime: Optional[Dict] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     view, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m view\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\dataset\\dataset.py:2420\u001b[39m, in \u001b[36mDataset.query\u001b[39m\u001b[34m(self, query_string, runtime, return_data)\u001b[39m\n\u001b[32m   2418\u001b[39m client = DeepLakeBackendClient(token=\u001b[38;5;28mself\u001b[39m._token)\n\u001b[32m   2419\u001b[39m org_id, ds_name = \u001b[38;5;28mself\u001b[39m.path[\u001b[32m6\u001b[39m:].split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2420\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2421\u001b[39m indices = response[\u001b[33m\"\u001b[39m\u001b[33mindices\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2422\u001b[39m view = \u001b[38;5;28mself\u001b[39m[indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\client\\client.py:480\u001b[39m, in \u001b[36mDeepLakeBackendClient.remote_query\u001b[39m\u001b[34m(self, org_id, ds_name, query_string)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremote_query\u001b[39m(\n\u001b[32m    468\u001b[39m     \u001b[38;5;28mself\u001b[39m, org_id: \u001b[38;5;28mstr\u001b[39m, ds_name: \u001b[38;5;28mstr\u001b[39m, query_string: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    469\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    470\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Queries a remote dataset.\u001b[39;00m\n\u001b[32m    471\u001b[39m \n\u001b[32m    472\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m \u001b[33;03m        Dict[str, Any]: The json response containing matching indicies and data from virtual tensors.\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mREMOTE_QUERY_SUFFIX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.json()\n\u001b[32m    487\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\client\\client.py:157\u001b[39m, in \u001b[36mDeepLakeBackendClient.request\u001b[39m\u001b[34m(self, method, relative_url, endpoint, params, data, files, json, headers, timeout)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m last_exception:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m last_exception\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43mcheck_response_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\client\\utils.py:54\u001b[39m, in \u001b[36mcheck_response_status\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResourceNotFoundException\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m422\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityException(message)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m423\u001b[39m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LockedException\n",
      "\u001b[31mUnprocessableEntityException\u001b[39m: The managed query engine is only available for datasets stored in the managed database [runtime = {\"tensor_db\": True}]."
     ]
    }
   ],
   "source": [
    "# Now create your retriever with tensor_db exec_option for TQL support\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 4,\n",
    "        \"exec_option\": \"tensor_db\"  # Required for TQL queries\n",
    "    }\n",
    ")\n",
    "\n",
    "# Now you can run your query\n",
    "results = retriever.get_relevant_documents(\"I want to watch a movie rated higher than 8.5\")\n",
    "\n",
    "# If you're using a managed Deep Lake instance, the tensor_db execution option is required for TQL queries.\n",
    "# For local datasets, you may need to ensure you're using the correct API methods compatible with your execution mode.\n",
    "# Alternatively, if you want to stick with the Python execution option, you should use a simple similarity search without TQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dccd34a4-dab4-4281-9657-7890a2504b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [GitHub Copilot]\n",
    "# How to Fix It\n",
    "# You need to either:\n",
    "# - 1. Use a managed Deep Lake dataset (cloud-hosted), or\n",
    "# - 2. Adjust your retrieval method to work with local datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343d1fb-5069-4550-ab72-c8530646d1c9",
   "metadata": {},
   "source": [
    "**Option 1: Use a managed Deep Lake dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba10916d-cc1c-4956-9125-0212b5b05613",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityException",
     "evalue": "The managed query engine is only available for datasets stored in the managed database [runtime = {\"tensor_db\": True}].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnprocessableEntityException\u001b[39m              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m retriever = vector_store.as_retriever(\n\u001b[32m     10\u001b[39m     search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m4\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexec_option\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtensor_db\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Now the query should work\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m results = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI want to watch a movie rated higher than 8.5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    180\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:410\u001b[39m, in \u001b[36mBaseRetriever.get_relevant_documents\u001b[39m\u001b[34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_name:\n\u001b[32m    409\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m] = run_name\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    257\u001b[39m _kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    263\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1074\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1072\u001b[39m _kwargs = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1076\u001b[39m     docs_and_similarities = (\n\u001b[32m   1077\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1078\u001b[39m             query, **_kwargs\n\u001b[32m   1079\u001b[39m         )\n\u001b[32m   1080\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:553\u001b[39m, in \u001b[36mDeepLake.similarity_search\u001b[39m\u001b[34m(self, query, k, **kwargs)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    495\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    496\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    497\u001b[39m     k: \u001b[38;5;28mint\u001b[39m = \u001b[32m4\u001b[39m,\n\u001b[32m    498\u001b[39m     **kwargs: Any,\n\u001b[32m    499\u001b[39m ) -> List[Document]:\n\u001b[32m    500\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    501\u001b[39m \u001b[33;03m    Return docs most similar to query.\u001b[39;00m\n\u001b[32m    502\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m        List[Document]: List of Documents most similar to the query vector.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\deeplake.py:451\u001b[39m, in \u001b[36mDeepLake._search\u001b[39m\u001b[34m(self, query, embedding, embedding_function, k, distance_metric, use_maximal_marginal_relevance, fetch_k, filter, return_score, exec_option, deep_memory, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(embedding.shape) > \u001b[32m1\u001b[39m:\n\u001b[32m    449\u001b[39m         embedding = embedding[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_maximal_marginal_relevance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membedding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_id_tensor_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m scores = result[\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    461\u001b[39m embeddings = result[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deeplake_vectorstore.py:319\u001b[39m, in \u001b[36mVectorStore.search\u001b[39m\u001b[34m(self, embedding_data, embedding_function, embedding, k, distance_metric, query, filter, exec_option, embedding_tensor, return_tensors, return_view, deep_memory, return_tql)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep_memory \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deep_memory:\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DeepMemoryAccessError()\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deep_memory\\deep_memory.py:60\u001b[39m, in \u001b[36muse_deep_memory.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_deep_memory \u001b[38;5;129;01mand\u001b[39;00m distance_metric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     58\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdistance_metric\u001b[39m\u001b[33m\"\u001b[39m] = DEFAULT_DEEPMEMORY_DISTANCE_METRIC\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\dataset_handlers\\client_side_dataset_handler.py:235\u001b[39m, in \u001b[36mClientSideDH.search\u001b[39m\u001b[34m(self, embedding_data, embedding_function, embedding, k, distance_metric, query, filter, exec_option, embedding_tensor, return_tensors, return_view, deep_memory, return_tql)\u001b[39m\n\u001b[32m    229\u001b[39m     distance_metric = index_maintenance.parse_index_distance_metric_from_params(\n\u001b[32m    230\u001b[39m         \u001b[38;5;28mself\u001b[39m.logger, \u001b[38;5;28mself\u001b[39m.distance_metric_index, distance_metric\n\u001b[32m    231\u001b[39m     )\n\u001b[32m    233\u001b[39m distance_metric = distance_metric \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_VECTORSTORE_DISTANCE_METRIC\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvector_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\vector_search.py:55\u001b[39m, in \u001b[36msearch\u001b[39m\u001b[34m(k, exec_option, deeplake_dataset, distance_metric, return_tensors, query, logger, filter, query_embedding, embedding_tensor, return_view, token, org_id, return_tql)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Searching function\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    query (Optional[str]) - TQL Query string for direct evaluation, without application of additional filters or vector search.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m \u001b[33;03m    return_tql (bool): Return TQL query used for the search. Defaults to False.\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m EXEC_OPTION_TO_SEARCH_TYPE: Dict[\u001b[38;5;28mstr\u001b[39m, Callable] = {\n\u001b[32m     51\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompute_engine\u001b[39m\u001b[33m\"\u001b[39m: vectorstore.indra_vector_search,\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m: vectorstore.python_vector_search,\n\u001b[32m     53\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtensor_db\u001b[39m\u001b[33m\"\u001b[39m: vectorstore.indra_vector_search,\n\u001b[32m     54\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEXEC_OPTION_TO_SEARCH_TYPE\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexec_option\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\vector_search.py:40\u001b[39m, in \u001b[36mvector_search\u001b[39m\u001b[34m(query, query_emb, exec_option, dataset, logger, filter, embedding_tensor, distance_metric, k, return_tensors, return_view, token, org_id, return_tql)\u001b[39m\n\u001b[32m     32\u001b[39m utils.check_indra_installation(exec_option)\n\u001b[32m     34\u001b[39m view, tql_filter = filter_utils.attribute_based_filtering_tql(\n\u001b[32m     35\u001b[39m     view=dataset,\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mfilter\u001b[39m=\u001b[38;5;28mfilter\u001b[39m,\n\u001b[32m     37\u001b[39m     logger=logger,\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindra_search_algorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mview\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\search_algorithm.py:205\u001b[39m, in \u001b[36msearch\u001b[39m\u001b[34m(query_embedding, distance_metric, deeplake_dataset, k, tql_string, tql_filter, embedding_tensor, runtime, return_tensors, return_view, token, org_id, return_tql)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m     searcher = SearchIndra(deeplake_dataset, org_id, token)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msearcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtql_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\search_algorithm.py:57\u001b[39m, in \u001b[36mSearchBasic.run\u001b[39m\u001b[34m(self, tql_string, return_view, return_tql, distance_metric, k, query_embedding, embedding_tensor, tql_filter, return_tensors)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     37\u001b[39m     tql_string: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     return_tensors: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     46\u001b[39m ):\n\u001b[32m     47\u001b[39m     tql_query = \u001b[38;5;28mself\u001b[39m._create_tql_string(\n\u001b[32m     48\u001b[39m         tql_string,\n\u001b[32m     49\u001b[39m         distance_metric,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m         return_tensors,\n\u001b[32m     55\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     view = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_view\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtql_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_view:\n\u001b[32m     63\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m view\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\indra\\search_algorithm.py:147\u001b[39m, in \u001b[36mSearchManaged._get_view\u001b[39m\u001b[34m(self, tql_query, runtime)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_view\u001b[39m(\u001b[38;5;28mself\u001b[39m, tql_query, runtime: Optional[Dict] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     view, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeeplake_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = data\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m view\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\core\\dataset\\dataset.py:2420\u001b[39m, in \u001b[36mDataset.query\u001b[39m\u001b[34m(self, query_string, runtime, return_data)\u001b[39m\n\u001b[32m   2418\u001b[39m client = DeepLakeBackendClient(token=\u001b[38;5;28mself\u001b[39m._token)\n\u001b[32m   2419\u001b[39m org_id, ds_name = \u001b[38;5;28mself\u001b[39m.path[\u001b[32m6\u001b[39m:].split(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2420\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremote_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2421\u001b[39m indices = response[\u001b[33m\"\u001b[39m\u001b[33mindices\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2422\u001b[39m view = \u001b[38;5;28mself\u001b[39m[indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\client\\client.py:480\u001b[39m, in \u001b[36mDeepLakeBackendClient.remote_query\u001b[39m\u001b[34m(self, org_id, ds_name, query_string)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremote_query\u001b[39m(\n\u001b[32m    468\u001b[39m     \u001b[38;5;28mself\u001b[39m, org_id: \u001b[38;5;28mstr\u001b[39m, ds_name: \u001b[38;5;28mstr\u001b[39m, query_string: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    469\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    470\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Queries a remote dataset.\u001b[39;00m\n\u001b[32m    471\u001b[39m \n\u001b[32m    472\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m \u001b[33;03m        Dict[str, Any]: The json response containing matching indicies and data from virtual tensors.\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mREMOTE_QUERY_SUFFIX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43morg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.json()\n\u001b[32m    487\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\client\\client.py:157\u001b[39m, in \u001b[36mDeepLakeBackendClient.request\u001b[39m\u001b[34m(self, method, relative_url, endpoint, params, data, files, json, headers, timeout)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m last_exception:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m last_exception\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43mcheck_response_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\client\\utils.py:54\u001b[39m, in \u001b[36mcheck_response_status\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResourceNotFoundException\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m422\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityException(message)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m423\u001b[39m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LockedException\n",
      "\u001b[31mUnprocessableEntityException\u001b[39m: The managed query engine is only available for datasets stored in the managed database [runtime = {\"tensor_db\": True}]."
     ]
    }
   ],
   "source": [
    "# Create a managed vector store (hosted on Deep Lake's cloud)\n",
    "# vector_store = DeepLake(\n",
    "#     dataset_path=\"hub://your-username/your-dataset\",  # Use your Activeloop Hub path\n",
    "#     embedding_function=embeddings,\n",
    "#     read_only=False\n",
    "# )\n",
    "\n",
    "# Create a retriever with tensor_db execution option\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\": 4, \"exec_option\": \"tensor_db\"}\n",
    ")\n",
    "\n",
    "# Now the query should work\n",
    "results = retriever.get_relevant_documents(\"I want to watch a movie rated higher than 8.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a870b-1992-419c-860e-112d7c322db6",
   "metadata": {},
   "source": [
    "**Option 2: Use a local dataset with Python execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8389706f-e226-4b30-9233-287eadabdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local vector store\n",
    "# vector_store = DeepLake(\n",
    "#     dataset_path=\"./my_local_deeplake_dataset\",\n",
    "#     embedding_function=embeddings,\n",
    "#     read_only=False\n",
    "# )\n",
    "\n",
    "# For local datasets, use the Python execution option (default)\n",
    "# but note that complex TQL filtering won't work - only basic similarity search\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# For basic similarity search without complex filtering:\n",
    "results = retriever.get_relevant_documents(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bcac43c-e77a-4a24-828f-16ece87fd8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'year': 1995, 'genre': 'animated'}, page_content='Toys come alive and have a blast doing so'),\n",
       " Document(metadata={'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.2}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...'),\n",
       " Document(metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea'),\n",
       " Document(metadata={'year': 1979, 'rating': 9.9, 'director': 'Andrei Tarkovsky', 'genre': 'science fiction'}, page_content='Three men walk into the Zone, three men walk out of the Zone')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15a50296-d3d1-4dd2-bbd3-7a02d7462478",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.get_relevant_documents(\"I want to watch a movie rated higher than 8.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1d68dbe-b0fc-447e-a7f9-a961ed6bfbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'year': 2010, 'director': 'Christopher Nolan', 'rating': 8.2}, page_content='Leo DiCaprio gets lost in a dream within a dream within a dream within a ...'),\n",
       " Document(metadata={'year': 2019, 'director': 'Greta Gerwig', 'rating': 8.3}, page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them'),\n",
       " Document(metadata={'year': 1995, 'genre': 'animated'}, page_content='Toys come alive and have a blast doing so'),\n",
       " Document(metadata={'year': 2006, 'director': 'Satoshi Kon', 'rating': 8.6}, page_content='A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
