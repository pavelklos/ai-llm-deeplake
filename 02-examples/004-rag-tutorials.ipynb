{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (RAG)\n",
    "- [RAG](https://docs.activeloop.ai/examples/rag)\n",
    "  - [RAG Quickstart](https://docs.activeloop.ai/examples/rag/quickstart)\n",
    "  - [RAG Tutorials](https://docs.activeloop.ai/examples/rag/tutorials)\n",
    "    - [Vector Store Basics](https://docs.activeloop.ai/examples/rag/tutorials/vector-store-basics)\n",
    "    - [Vector Search Options](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options)\n",
    "      - [**LangChain API**](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/langchain-api)\n",
    "      - [Deep Lake Vector Store API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/vector-store-api)\n",
    "      - [Managed Database REST API](https://docs.activeloop.ai/examples/rag/tutorials/vector-search-options/rest-api)\n",
    "    - [Customizing Your Vector Store](https://docs.activeloop.ai/examples/rag/tutorials/step-4-customizing-vector-stores)\n",
    "    - [Image Similarity Search](https://docs.activeloop.ai/examples/rag/tutorials/image-similarity-search)\n",
    "    - [Improving Search Accuracy using Deep Memory](https://docs.activeloop.ai/examples/rag/tutorials/deepmemory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9134e12-66df-4b48-915d-a3b9f5e1c550",
   "metadata": {},
   "source": [
    "## RAG Tutorials (Vector Search Options) (LangChain API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd50d776-39c1-4aa8-84d0-a22576b55a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8ecf67-eddb-4103-b34c-84124923c547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-deeplake\n",
      "  Using cached langchain_deeplake-0.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-deeplake to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 3.0.11, 3.2.0, 3.8.26\n",
      "ERROR: Could not find a version that satisfies the requirement deeplake>=4.1 (from langchain-deeplake) (from versions: 0.0.1, 2.8.6, 2.8.7, 3.0.0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.0.6, 3.0.7, 3.0.8, 3.0.9, 3.0.10, 3.0.12, 3.0.13, 3.0.14, 3.0.15, 3.0.16, 3.0.17, 3.0.18, 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.1.4, 3.1.5, 3.1.6, 3.1.7, 3.1.8, 3.1.9, 3.1.10, 3.1.11, 3.1.12, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.2.5, 3.2.6, 3.2.7, 3.2.8, 3.2.9, 3.2.10, 3.2.11, 3.2.12, 3.2.13, 3.2.14, 3.2.15, 3.2.16, 3.2.17, 3.2.18, 3.2.19, 3.2.20, 3.2.21, 3.2.22, 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.4.4, 3.5.0, 3.5.1, 3.5.2, 3.5.3, 3.5.4, 3.6.0, 3.6.1, 3.6.2, 3.6.3, 3.6.4, 3.6.5, 3.6.6, 3.6.7, 3.6.8, 3.6.9, 3.6.10, 3.6.11, 3.6.12, 3.6.13, 3.6.14, 3.6.15, 3.6.16, 3.6.17, 3.6.18, 3.6.19, 3.6.20, 3.6.21, 3.6.22, 3.6.23, 3.6.24, 3.6.25, 3.6.26, 3.7.0, 3.7.1, 3.7.2, 3.7.3, 3.8.0, 3.8.1, 3.8.2, 3.8.3, 3.8.4, 3.8.5, 3.8.6, 3.8.7, 3.8.8, 3.8.9, 3.8.10, 3.8.11, 3.8.12, 3.8.13, 3.8.14, 3.8.15, 3.8.16, 3.8.17, 3.8.18, 3.8.19, 3.8.20, 3.8.21, 3.8.22, 3.8.23, 3.8.24, 3.8.25, 3.8.27, 3.8.28, 3.9.0, 3.9.1, 3.9.2, 3.9.3, 3.9.4, 3.9.5, 3.9.6, 3.9.7, 3.9.8, 3.9.9, 3.9.10, 3.9.11, 3.9.12, 3.9.13, 3.9.14, 3.9.15, 3.9.16, 3.9.17, 3.9.18, 3.9.19, 3.9.20, 3.9.21, 3.9.22, 3.9.23, 3.9.24, 3.9.25, 3.9.26, 3.9.27, 3.9.28, 3.9.29, 3.9.30, 3.9.31, 3.9.32, 3.9.33, 3.9.34, 3.9.35, 3.9.36, 3.9.37, 3.9.38, 3.9.39, 3.9.40, 3.9.41, 3.9.42, 3.9.43, 3.9.44)\n",
      "ERROR: No matching distribution found for deeplake>=4.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U langchain-deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6025cec-0d4f-4196-9002-bb6b70f72e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\projects\\ai-llm-deeplake\\.venv\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from langchain.vectorstores import DeepLake\n",
    "from langchain_community.vectorstores import DeepLake\n",
    "# from langchain_deeplake.vectorstores import DeeplakeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.llms import OpenAIChat\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override = True)\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')\n",
    "activeloop_token = os.getenv('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58d999e-bf94-4864-871a-823779e2f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcbbeda-986c-43da-84bd-c2fdaf983400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_24268\\3800493300.py:11: LangChainDeprecationWarning: This class is deprecated and will be removed in a future version. You can swap to using the `DeeplakeVectorStore` implementation in `langchain-deeplake`. Please do not submit further PRs to this class.See <https://github.com/activeloopai/langchain-deeplake>\n",
      "  db = DeepLake(dataset_path = vector_store_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://activeloop/paul_graham_essay already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "# Load the same vector store used in the Quickstart and run embeddings search\n",
    "#   based on a user prompt using the LangChain API\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = <OPENAI_API_KEY>\n",
    "\n",
    "vector_store_path = 'hub://activeloop/paul_graham_essay'\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model = 'text-embedding-ada-002')\n",
    "\n",
    "# Re-load the vector store\n",
    "db = DeepLake(dataset_path = vector_store_path, \n",
    "              embedding = embedding_function, \n",
    "              read_only = True)\n",
    "\n",
    "# [langchain-deeplake]\n",
    "# - https://github.com/activeloopai/langchain-deeplake\n",
    "# db = DeeplakeVectorStore(dataset_path=dataset_path,\n",
    "#                          embedding_function=embeddings,\n",
    "#                          read_only=True)\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAIChat(model = 'gpt-3.5-turbo'),\n",
    "qa = RetrievalQA.from_chain_type(llm=ChatOpenAI(model = MODEL_GPT),\n",
    "                                 chain_type = 'stuff', \n",
    "                                 retriever = db.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa4165-ebcf-4aa7-9194-8fe0d76c9de4",
   "metadata": {},
   "source": [
    "### Vector Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a556cc48-cade-41f1-9c2a-7ee348227dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'What are the first programs he tried writing?'\n",
    "\n",
    "query_docs = db.similarity_search(query = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4093db1-2d85-47d6-8fab-20de1e123910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
      "\n",
      "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n"
     ]
    }
   ],
   "source": [
    "query_docs[0].page_content\n",
    "print(query_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d275e3b-f065-45c7-af2b-5d54ebeb5214",
   "metadata": {},
   "source": [
    "### Vector Search in an LLM Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5ae2b9-2a42-4549-a8bd-069fbbef705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the first programs he tried writing?',\n",
       " 'result': 'The first programs he tried writing were on the IBM 1401 that the school district used for data processing.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qa = RetrievalQA.from_chain_type(llm = OpenAIChat(model = 'gpt-3.5-turbo'),\n",
    "qa = RetrievalQA.from_chain_type(llm = ChatOpenAI(model = MODEL_GPT),\n",
    "                                 chain_type = 'stuff', \n",
    "                                 retriever = db.as_retriever())\n",
    "\n",
    "# qa.run(prompt)\n",
    "qa.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7ff2f-3d31-4510-b15a-abead25f6e6f",
   "metadata": {},
   "source": [
    "### Vector Search Using the Managed Tensor Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be43c6a3-065e-47a9-b30f-3fae4c707c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DeepLake(dataset_path = \"hub://<org_id>/<dataset_name>\", \n",
    "#               runtime = {\"tensor_db\": True},\n",
    "#               embedding = embedding_function\n",
    "#              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
