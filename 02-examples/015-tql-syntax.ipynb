{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93495a2e-3e04-4cb8-81d7-a00f9dc0b4f4",
   "metadata": {},
   "source": [
    "# EXAMPLES (TQL)\n",
    "- [Tensor Query Language (TQL)](https://docs.activeloop.ai/examples/tql)\n",
    "  - [**TQL Syntax**](https://docs.activeloop.ai/examples/tql/syntax)\n",
    "  - [Index for ANN Search](https://docs.activeloop.ai/examples/tql/ann-index)\n",
    "    - [Caching and Optimization](https://docs.activeloop.ai/examples/tql/ann-index/caching-and-optimization)\n",
    "  - [Sampling Datasets](https://docs.activeloop.ai/examples/tql/sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b359eee8-d7e0-46e2-80cd-850dedd88d6c",
   "metadata": {},
   "source": [
    "## TQL Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72895c1-3222-42f2-b7ae-22b417fce35a",
   "metadata": {},
   "source": [
    "### Query syntax for the Tensor Query Language (TQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd626a7-5c75-4a97-a867-61c90abc8ba4",
   "metadata": {},
   "source": [
    "#### CONTAINS and =="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55e11d-8d94-48f1-82a6-669399199f88",
   "metadata": {},
   "source": [
    "*Exact match, which generally requires that the sample has 1 value, i.e. no lists or multi-dimensional arrays*\n",
    "```\n",
    "select * where tensor_name == 'text_value'   # If value is text\n",
    "select * where tensor_name == numeric_value  # If values is numeric\n",
    "\n",
    "select * where contains(tensor_name, 'text_value')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a88ab-36eb-42f7-8b7b-2e339739187c",
   "metadata": {},
   "source": [
    "*Tensor or group names with special characters should be wrapped with double-quotes:*\n",
    "```\n",
    "select * where contains(\"tensor-name\", 'text_value')\n",
    "select * where \"tensor_name/group_name\" == numeric_value\n",
    "```\n",
    "*Make sure to wrap double-quotes with escape characters in Python:*\n",
    "```\n",
    "select * where contains(\\\"tensor-name\\\", 'text_value')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230354f-16c6-449f-883f-da42930a2af5",
   "metadata": {},
   "source": [
    "#### SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccd0cbd-5bf6-4c66-9dc7-fb73580a227b",
   "metadata": {},
   "source": [
    "```\n",
    "select * where shape(tensor_name)[dimension_index] > numeric_value \n",
    "select * where shape(tensor_name)[1] > numeric_value # Second array dimension > value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c33c9e-27a0-43d7-9e89-4e727d0d27a7",
   "metadata": {},
   "source": [
    "#### LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe586f-63eb-423a-829f-6cb817f86acc",
   "metadata": {},
   "source": [
    "```\n",
    "select * where contains(tensor_name, 'text_value') limit num_samples\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ee80b-b2f1-4478-a9be-83842e9d0101",
   "metadata": {},
   "source": [
    "#### AND, OR, NOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d2997-996b-48fc-8820-3e462b518811",
   "metadata": {},
   "source": [
    "```\n",
    "select * where contains(tensor_name, 'text_value') and NOT contains(tensor_name_2, numeric_value)\n",
    "select * where contains(tensor_name, 'text_value') or tensor_name_2 == numeric_value\n",
    "\n",
    "select * where (contains(tensor_name, 'text_value') and shape(tensor_name_2)[dimension_index]>numeric_value) or contains(tensor_name, 'text_value_2')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24de89f-1dfa-4302-a145-8357941b7bdf",
   "metadata": {},
   "source": [
    "#### UNION and INTERSECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2d49c-d7e0-444b-80b7-e98f686a1f6a",
   "metadata": {},
   "source": [
    "```\n",
    "(select * where contains(tensor_name, 'value')) intersect (select * where contains(tensor_name, 'value_2'))\n",
    "\n",
    "(select * where contains(tensor_name, 'value') limit 100) union (select * where shape(tensor_name)[0] > numeric_value limit 100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd71b4-1c36-453f-94d5-f668c7e8103d",
   "metadata": {},
   "source": [
    "#### ORDER BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81516d-057b-45fb-9ba1-fe18ce64f2d2",
   "metadata": {},
   "source": [
    "*Order by requires that sample is numeric and has 1 value,*<br>\n",
    "*i.e. no lists or multi-dimensional arrays*<br>\n",
    "*The default order is ASCENDING (asc)*\n",
    "```\n",
    "select * where contains(tensor_name, 'text_value') order by tensor_name asc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fa66a-9e24-4aad-b5fc-db238b9c89ad",
   "metadata": {},
   "source": [
    "#### ANY, ALL, and ALL_STRICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1deb5e-e998-42a5-9a4c-7a2905397a13",
   "metadata": {},
   "source": [
    "*all adheres to NumPy and list logic where all(empty_sample) returns True*<br>\n",
    "*all_strict is more intuitive for queries so all_strict(empty_sample) returns False*\n",
    "```\n",
    "select * where all(tensor_name==0) # Returns True for empty samples\n",
    "\n",
    "select * where all_strict(tensor_name[:,2]>numeric_value) # Returns False for empty samples\n",
    "\n",
    "select * where any(tensor_name[0:6]>numeric_value)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935273da-1c24-487d-b164-b7e6ab27afc9",
   "metadata": {},
   "source": [
    "#### IN and BETWEEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b95f3-dbcd-4d89-8d55-4ade34d00be8",
   "metadata": {},
   "source": [
    "*Only works for scalar numeric values and text references to class_names*\n",
    "```\n",
    "select * where tensor_name in (1, 2, 6, 10)\n",
    "\n",
    "select * where class_label_tensor_name in ('car', 'truck')\n",
    "\n",
    "select * where tensor_name between 5 and 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb00a9-36c1-4e62-b251-abe46cfce18b",
   "metadata": {},
   "source": [
    "#### LOGICAL_AND and LOGICAL_OR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b7b86-7d3c-4cf0-b94d-089ebd37b4a9",
   "metadata": {},
   "source": [
    "```\n",
    "select * where any(logical_and(tensor_name_1[:,3]>numeric_value, tensor_name_2 == 'text_value'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0717d5-7eb9-41b7-b608-685afd14c770",
   "metadata": {},
   "source": [
    "#### REFERENCING SAMPLES IN EXISTING TENORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b8e0b-294a-4a3c-b0ff-a635935f1a0c",
   "metadata": {},
   "source": [
    "```\n",
    "# Select based on index (row_number)\n",
    "select * where row_number() == 10\n",
    "\n",
    "# Referencing values of of a tensor at index (row_number)\n",
    "select * order by l2_norm(<tensor_name> - data(<tensor_name>, index))\n",
    "\n",
    "# Finds rows of data with embeddings most similar to index 10\n",
    "select * order by l2_norm(embedding - data(embedding, 10))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abce13-09cc-4590-a54a-c46d7fd54e42",
   "metadata": {},
   "source": [
    "#### SAMPLE BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe202d4-c5ed-4c72-b74a-adde131cd9e5",
   "metadata": {},
   "source": [
    "```\n",
    "select * sample by weight_choice(expression_1: weight_1, expression_2: weight_2, ...)\n",
    "    replace True limit N\n",
    "```\n",
    "- *weight_choice resolves the weight that is used when multiple expressions evaluate to True for a given sample. Options are max_weight, sum_weight. For example, if weight_choice is max_weight, then the maximum weight will be chosen for that sample.*\n",
    "- *replace determines whether samples should be drawn with replacement. It defaults to True.*\n",
    "- *limit specifies the number of samples that should be returned. If unspecified, the sampler will return the number of samples corresponding to the length of the dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ad033-85ec-4391-a1f8-a1609148a8f9",
   "metadata": {},
   "source": [
    "#### EMBEDDING SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d3df6-997a-4475-929f-78b823617fa8",
   "metadata": {},
   "source": [
    "*Deep Lake supports several vector operations for embedding search. Typically, vector operations are called by returning data ordered by the score based on the vector search method.*\n",
    "```\n",
    "select * from (select tensor_1, tensor_2, <VECTOR_OPERATION> as score) order by score desc limit 10\n",
    "```\n",
    "*THE SUPPORTED VECTOR_OPERATIONS ARE:*\n",
    "```\n",
    "l1_norm(<embedding_tensor> - ARRAY[<search_embedding>]) # Order should be asc\n",
    "\n",
    "l2_norm(<embedding_tensor> - ARRAY[<search_embedding>]) # Order should be asc\n",
    "\n",
    "linf_norm(<embedding_tensor> - ARRAY[<search_embedding>]) # Order should be asc\n",
    "\n",
    "cosine_similarity(<embedding_tensor>, ARRAY[<search_embedding>]) # Order should be desc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a94a5-bbf9-4882-8ea4-01e40df093b3",
   "metadata": {},
   "source": [
    "#### VIRTUAL TENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb5195-2ea6-44dc-a958-659a5b8489ea",
   "metadata": {},
   "source": [
    "*Virtual tensors are the result of a computation and are not tensors in the Deep Lake dataset. However, they can be treated as tensors in the API.*<br>\n",
    "*When combining embedding search with filtering (where conditions), the filter condition is evaluated prior to the embedding search.*\n",
    "```\n",
    "# \"score\" is a virtual tensor\n",
    "select * from (select tensor_1, tensor_2, <VECTOR_OPERATION> as score) order by score desc limit 10\n",
    "\n",
    "# \"box_beyond_image\" is a virtual tensor\n",
    "select *, any(boxes[:,0])<0 as box_beyond_image where ....\n",
    "\n",
    "#  \"tensor_sum\" is a virtual tensor\n",
    "select *, tensor_1 + tensor_3 as tensor_sum where ......\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bfeda-97b2-4c4a-87da-e29ef747a247",
   "metadata": {},
   "source": [
    "#### GROUP BY AND UNGROUP BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee00816a-608b-4a6f-b415-44e893b1f15e",
   "metadata": {},
   "source": [
    "*Group by creates a sequence of data based on the common properties that are being grouped (i.e. frames into videos). Ungroup by splits sequences into their individual elements (i.e. videos into images).*\n",
    "```\n",
    "select * group by label, video_id # Groups all data with the same label and video_id in to the same sequence\n",
    "\n",
    "select * ungroup by split # Splits sequences into their original pieces\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80e6f4-137a-4e34-a908-8d8890071bac",
   "metadata": {},
   "source": [
    "#### EXPAND BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab643d6-66a7-4864-89e8-fc44bedd3531",
   "metadata": {},
   "source": [
    "*Expand by  includes samples before and after a query condition is satisfied.*\n",
    "```\n",
    "select * where <condition> expand by rows_before, rows_after\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
